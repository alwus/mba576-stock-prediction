{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddba2e6-16b6-491a-b687-98a02d511fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import yfinance as yf\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# one-time download of nltk stopwords and wordnet resources required\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, TimeSeriesSplit\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import hstack\n",
    "from scipy import sparse\n",
    "\n",
    "#!pip install scikeras\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Embedding, GlobalAveragePooling1D, Concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc18b14-7ed7-4331-8056-e14950ec15ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for google colab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# adjust as needed\n",
    "# base_path = '/content/drive/My Drive/Colab Notebooks/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "980fe6ed-30bc-418e-a23b-add41b2cb7fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'analyst_ratings_processed.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Let pandas handle date parsing internally — it's optimized and faster\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m news_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manalyst_ratings_processed.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, parse_dates\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[1;32m      3\u001b[0m news_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(news_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m], utc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m# removed .dt.date\u001b[39;00m\n\u001b[1;32m      4\u001b[0m news_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m news_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mtz_localize(\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;66;03m# new line of code to remove tz infor\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'analyst_ratings_processed.csv'"
     ]
    }
   ],
   "source": [
    "# Let pandas handle date parsing internally — it's optimized and faster\n",
    "news_df = pd.read_csv('analyst_ratings_processed.csv', parse_dates=['date']).dropna()\n",
    "news_df['date'] = pd.to_datetime(news_df['date'], utc=True) # removed .dt.date\n",
    "news_df['date'] = news_df['date'].dt.tz_localize(None) # new line of code to remove tz infor\n",
    "\n",
    "prices_df = pd.read_csv('prices-split-adjusted.csv', parse_dates=['date']).dropna()\n",
    "prices_df['date'] = pd.to_datetime(prices_df['date']) # changed to get pd.Timestamp\n",
    "\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "734790b6-34f4-4563-9d6f-042f74929e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>friday_date</th>\n",
       "      <th>friday_close</th>\n",
       "      <th>monday</th>\n",
       "      <th>tuesday</th>\n",
       "      <th>monday_open</th>\n",
       "      <th>tuesday_open</th>\n",
       "      <th>next_open</th>\n",
       "      <th>target</th>\n",
       "      <th>open_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WLTW</td>\n",
       "      <td>2016-01-08</td>\n",
       "      <td>116.620003</td>\n",
       "      <td>2016-01-11</td>\n",
       "      <td>2016-01-12</td>\n",
       "      <td>117.010002</td>\n",
       "      <td>115.510002</td>\n",
       "      <td>117.010002</td>\n",
       "      <td>UP</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WLTW</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>112.529999</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>2016-01-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113.660004</td>\n",
       "      <td>113.660004</td>\n",
       "      <td>UP</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WLTW</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>111.949997</td>\n",
       "      <td>2016-01-25</td>\n",
       "      <td>2016-01-26</td>\n",
       "      <td>111.320000</td>\n",
       "      <td>110.419998</td>\n",
       "      <td>111.320000</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WLTW</td>\n",
       "      <td>2016-01-29</td>\n",
       "      <td>114.470001</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>2016-02-02</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>113.250000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WLTW</td>\n",
       "      <td>2016-02-05</td>\n",
       "      <td>114.019997</td>\n",
       "      <td>2016-02-08</td>\n",
       "      <td>2016-02-09</td>\n",
       "      <td>113.300003</td>\n",
       "      <td>111.169998</td>\n",
       "      <td>113.300003</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker friday_date  friday_close     monday    tuesday  monday_open  \\\n",
       "0   WLTW  2016-01-08    116.620003 2016-01-11 2016-01-12   117.010002   \n",
       "1   WLTW  2016-01-15    112.529999 2016-01-18 2016-01-19          NaN   \n",
       "2   WLTW  2016-01-22    111.949997 2016-01-25 2016-01-26   111.320000   \n",
       "3   WLTW  2016-01-29    114.470001 2016-02-01 2016-02-02   114.000000   \n",
       "4   WLTW  2016-02-05    114.019997 2016-02-08 2016-02-09   113.300003   \n",
       "\n",
       "   tuesday_open   next_open target open_day  \n",
       "0    115.510002  117.010002     UP   Monday  \n",
       "1    113.660004  113.660004     UP  Tuesday  \n",
       "2    110.419998  111.320000   DOWN   Monday  \n",
       "3    113.250000  114.000000   DOWN   Monday  \n",
       "4    111.169998  113.300003   DOWN   Monday  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean column names\n",
    "news_df = news_df.rename(columns={'title': 'headline', 'stock': 'ticker'})\n",
    "prices_df = prices_df.rename(columns={'symbol': 'ticker'})\n",
    "\n",
    "# Extract valid Fridays\n",
    "friday_prices = prices_df[prices_df['date'].dt.dayofweek == 4][['ticker', 'date', 'close']].copy()\n",
    "friday_prices = friday_prices.rename(columns={'date': 'friday_date', 'close': 'friday_close'})\n",
    "\n",
    "# Create DataFrame of potential comparisons\n",
    "friday_prices['monday'] = friday_prices['friday_date'] + pd.Timedelta(days=3)\n",
    "friday_prices['tuesday'] = friday_prices['friday_date'] + pd.Timedelta(days=4)\n",
    "\n",
    "# Get Monday open prices\n",
    "monday_open = prices_df[['ticker', 'date', 'open']].copy()\n",
    "monday_open = monday_open.rename(columns={'date': 'monday', 'open': 'monday_open'})\n",
    "\n",
    "# Get Tuesday open prices\n",
    "tuesday_open = prices_df[['ticker', 'date', 'open']].copy()\n",
    "tuesday_open = tuesday_open.rename(columns={'date': 'tuesday', 'open': 'tuesday_open'})\n",
    "\n",
    "# Merge to attach possible Monday and Tuesday open prices\n",
    "merged = pd.merge(friday_prices, monday_open, on=['ticker', 'monday'], how='left')\n",
    "merged = pd.merge(merged, tuesday_open, on=['ticker', 'tuesday'], how='left')\n",
    "\n",
    "# Use Monday open if it exists, otherwise fallback to Tuesday open\n",
    "merged['next_open'] = merged['monday_open'].combine_first(merged['tuesday_open'])\n",
    "\n",
    "# If both Monday and Tuesday are missing (market closed 2 days), drop the row\n",
    "merged = merged.dropna(subset=['next_open', 'friday_close'])\n",
    "\n",
    "# create target variable: 'UP' if Monday's open is higher than Friday's close, 'DOWN' otherwise\n",
    "merged['target'] = np.where(merged['next_open'] > merged['friday_close'], 'UP', 'DOWN')\n",
    "\n",
    "# keep track of Monday or Tuesday opens\n",
    "merged['open_day'] = np.where(\n",
    "    ~merged['monday_open'].isna(), 'Monday',\n",
    "    np.where(~merged['tuesday_open'].isna(), 'Tuesday', 'Missing')\n",
    ")\n",
    "\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52c1e469-f227-4d99-ae09-6dbcb879f377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time required to build weekly headline lists (sec): 49.8\n"
     ]
    }
   ],
   "source": [
    "# track time required to list weekly headlines\n",
    "start = time.time()\n",
    "\n",
    "# ensure news_df converted to datetime\n",
    "news_df['date'] = pd.to_datetime(news_df['date'])\n",
    "\n",
    "# determine actual open date used\n",
    "merged['open_date_used'] = merged['monday']\n",
    "merged.loc[merged['monday_open'].isna(), 'open_date_used'] = merged['tuesday']\n",
    "merged['open_date_used'] = pd.to_datetime(merged['open_date_used'])\n",
    "\n",
    "# create start and end date ranges\n",
    "merged['start_date'] = merged['open_date_used'] - pd.Timedelta(days=7)\n",
    "merged['end_date'] = merged['open_date_used'] - pd.Timedelta(days=1)\n",
    "\n",
    "# reset index to track original rows\n",
    "merged = merged.reset_index().rename(columns={'index': 'orig_index'})\n",
    "\n",
    "# join on ticker to create expanded set of candidate news rows\n",
    "news_expanded = pd.merge(\n",
    "    merged[['orig_index', 'ticker', 'start_date', 'end_date']],\n",
    "    news_df[['ticker', 'date', 'headline']],\n",
    "    on='ticker',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# filter news within the 7-day window\n",
    "mask = (news_expanded['date'] >= news_expanded['start_date']) & \\\n",
    "       (news_expanded['date'] <= news_expanded['end_date'])\n",
    "news_expanded = news_expanded[mask]\n",
    "\n",
    "# aggregate headlines by row\n",
    "headline_agg = news_expanded.groupby('orig_index')['headline'] \\\n",
    "    .apply(lambda x: \" \".join(x)).reset_index()\n",
    "\n",
    "# merge aggregated headlines back into merged\n",
    "merged = pd.merge(merged, headline_agg, on='orig_index', how='left')\n",
    "merged = merged.rename(columns={'headline': 'weekly_headlines'})\n",
    "\n",
    "# drop empty headline rows\n",
    "merged = merged[merged['weekly_headlines'].str.strip().notna()]\n",
    "\n",
    "# clean temp columns\n",
    "merged.drop(columns=['start_date', 'end_date', 'orig_index'], inplace=True)\n",
    "\n",
    "headline_list_time = time.time() - start\n",
    "print('Time required to build weekly headline lists (sec): {:.1f}'.format(headline_list_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c4d7b0c-7286-4c97-b3df-686f48a0f948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged.to_csv(\"merged_with_weekly_headlines.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b885263f-4511-4ac0-abd6-1029fbc8e657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process text information\n",
    "\n",
    "# Setup\n",
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation)\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "# Cleaning function\n",
    "def clean(doc):\n",
    "    # Lowercase and remove stopwords\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    # Remove punctuation\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    # Lemmatize words\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    return normalized\n",
    "\n",
    "# Apply to 'weekly_headlines' column\n",
    "merged['weekly_headlines_clean'] = merged['weekly_headlines'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4093a1b4-7e70-49dd-9aff-d7a070dfd20e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>friday_date</th>\n",
       "      <th>friday_close</th>\n",
       "      <th>monday</th>\n",
       "      <th>tuesday</th>\n",
       "      <th>monday_open</th>\n",
       "      <th>tuesday_open</th>\n",
       "      <th>next_open</th>\n",
       "      <th>target</th>\n",
       "      <th>open_day</th>\n",
       "      <th>open_date_used</th>\n",
       "      <th>weekly_headlines</th>\n",
       "      <th>weekly_headlines_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>AAP</td>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>40.639999</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>2010-01-12</td>\n",
       "      <td>40.720001</td>\n",
       "      <td>39.430000</td>\n",
       "      <td>40.720001</td>\n",
       "      <td>UP</td>\n",
       "      <td>Monday</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>Advance Auto Parts – A Turnaround Candidate (AAP)</td>\n",
       "      <td>advance auto part – turnaround candidate aap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>ABC</td>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>26.049999</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>2010-01-12</td>\n",
       "      <td>26.240000</td>\n",
       "      <td>26.320000</td>\n",
       "      <td>26.240000</td>\n",
       "      <td>UP</td>\n",
       "      <td>Monday</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>Benzinga’s Top Downgrades (WEN, CMP, ACL, PPDI...</td>\n",
       "      <td>benzinga’s top downgrade wen cmp acl ppdi abc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>ACN</td>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>42.570000</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>2010-01-12</td>\n",
       "      <td>42.439999</td>\n",
       "      <td>42.209999</td>\n",
       "      <td>42.439999</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>Monday</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>Economic Effects Of Tiger’s Misses! Is There A...</td>\n",
       "      <td>economic effect tiger’s miss sex tape tiger wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>ADBE</td>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>36.689999</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>2010-01-12</td>\n",
       "      <td>36.680000</td>\n",
       "      <td>36.139999</td>\n",
       "      <td>36.680000</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>Monday</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>Silicon Valley Reeling Under High Vacancy Rate...</td>\n",
       "      <td>silicon valley reeling high vacancy rate cbg a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>AET</td>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>32.700001</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>2010-01-12</td>\n",
       "      <td>32.770000</td>\n",
       "      <td>32.630001</td>\n",
       "      <td>32.770000</td>\n",
       "      <td>UP</td>\n",
       "      <td>Monday</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>Positive Outlook And Better Guidance Results I...</td>\n",
       "      <td>positive outlook better guidance result upgrad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ticker friday_date  friday_close     monday    tuesday  monday_open  \\\n",
       "52    AAP  2010-01-08     40.639999 2010-01-11 2010-01-12    40.720001   \n",
       "54    ABC  2010-01-08     26.049999 2010-01-11 2010-01-12    26.240000   \n",
       "56    ACN  2010-01-08     42.570000 2010-01-11 2010-01-12    42.439999   \n",
       "57   ADBE  2010-01-08     36.689999 2010-01-11 2010-01-12    36.680000   \n",
       "66    AET  2010-01-08     32.700001 2010-01-11 2010-01-12    32.770000   \n",
       "\n",
       "    tuesday_open  next_open target open_day open_date_used  \\\n",
       "52     39.430000  40.720001     UP   Monday     2010-01-11   \n",
       "54     26.320000  26.240000     UP   Monday     2010-01-11   \n",
       "56     42.209999  42.439999   DOWN   Monday     2010-01-11   \n",
       "57     36.139999  36.680000   DOWN   Monday     2010-01-11   \n",
       "66     32.630001  32.770000     UP   Monday     2010-01-11   \n",
       "\n",
       "                                     weekly_headlines  \\\n",
       "52  Advance Auto Parts – A Turnaround Candidate (AAP)   \n",
       "54  Benzinga’s Top Downgrades (WEN, CMP, ACL, PPDI...   \n",
       "56  Economic Effects Of Tiger’s Misses! Is There A...   \n",
       "57  Silicon Valley Reeling Under High Vacancy Rate...   \n",
       "66  Positive Outlook And Better Guidance Results I...   \n",
       "\n",
       "                               weekly_headlines_clean  \n",
       "52       advance auto part – turnaround candidate aap  \n",
       "54      benzinga’s top downgrade wen cmp acl ppdi abc  \n",
       "56  economic effect tiger’s miss sex tape tiger wo...  \n",
       "57  silicon valley reeling high vacancy rate cbg a...  \n",
       "66  positive outlook better guidance result upgrad...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "2e81f964-83c5-4de7-8ade-e81bb8ac0906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing text...\n"
     ]
    }
   ],
   "source": [
    "# vectorize cleaned weekly headlines\n",
    "print(\"Vectorizing text...\")\n",
    "tfidf = TfidfVectorizer(max_features=5000)  # Limit features for memory\n",
    "X_text = tfidf.fit_transform(merged['weekly_headlines_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "283fb46f-496b-490b-95d7-371bff96f5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Time required to train model (sec): 299.0\n"
     ]
    }
   ],
   "source": [
    "# train randomforest classifier and measure train time\n",
    "start = time.time()\n",
    "\n",
    "X = X_text\n",
    "y = merged['target']\n",
    "\n",
    "# Save original indices\n",
    "original_indices = merged.index\n",
    "\n",
    "X_train, X_test, y_train, y_test, train_idx, test_idx = train_test_split(\n",
    "    X, y, original_indices, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training model...\")\n",
    "clf = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "train_time = time.time() - start\n",
    "print('Time required to train model (sec): {:.1f}'.format(train_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "0654c238-00a3-4139-8624-686410b12672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "      DOWN    UP\n",
      "DOWN  3960  2756\n",
      "UP    2945  3751\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DOWN       0.57      0.59      0.58      6716\n",
      "          UP       0.58      0.56      0.57      6696\n",
      "\n",
      "    accuracy                           0.57     13412\n",
      "   macro avg       0.57      0.57      0.57     13412\n",
      "weighted avg       0.57      0.57      0.57     13412\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "labels = sorted(y.unique())\n",
    "cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "print(cm_df)\n",
    "\n",
    "# classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "f9cf7993-9f89-415b-899e-4bf0bf639566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ticker  prob_up                                           headline\n",
      "49572    MPC    1.000  oppenheimer 3 healthcare stock 2 energy stock buy\n",
      "7821    URBN    0.998                         market rangebound 11302010\n",
      "1536     ETR    0.998      investor need pay attention dividend etf 2010\n",
      "9234    ATVI    0.998                          hysteria kill market nvax\n",
      "41418    MAR    0.996                   top exdividend stock may 21 2014\n",
      "1590    PBCT    0.996   real estate etf continue face major hurdle ahead\n",
      "40607      L    0.994  benzinga weekly preview earnings season contin...\n",
      "40640    NOV    0.994  benzinga weekly preview earnings season contin...\n",
      "10610      D    0.992  morgan stanley discontinues coverage ed xel ei...\n",
      "30626     MO    0.992  four large cap buyout candidate healthy divide...\n",
      "56467     CA    0.992                    top 20 wall street analyst 2015\n",
      "10598    CMS    0.992  morgan stanley discontinues coverage ed xel ei...\n",
      "43496   SPLS    0.992  benzinga weekly preview several large retailer...\n",
      "30584   GRMN    0.992  four large cap buyout candidate healthy divide...\n",
      "41032    KSS    0.992  benzinga weekly preview several large retailer...\n",
      "1900    BBBY    0.990  retailer partying like 2007 ralph lauren go be...\n",
      "52242    AMP    0.988  morgan stanley top 15 vintage value stock pick...\n",
      "10648    HCN    0.984  morgan keegan analyzes publicly traded healthc...\n",
      "37742    LNC    0.982       slideshow top 10 high dive sp 500 stock 2013\n",
      "21273    ITW    0.982  caterpillar discover financial illinois primar...\n"
     ]
    }
   ],
   "source": [
    "# get predicted probabilities of going 'UP'\n",
    "y_proba = clf.predict_proba(X_test)\n",
    "proba_up = y_proba[:, 1]\n",
    "\n",
    "# create dataframe to assess top predictions\n",
    "results = pd.DataFrame({\n",
    "    'ticker': merged.loc[test_idx, 'ticker'].values,\n",
    "    'prob_up': proba_up,\n",
    "    'true_label': y_test,\n",
    "    'headline': merged.loc[test_idx, 'weekly_headlines_clean'].values\n",
    "})\n",
    "\n",
    "# find top 20 mosst confident predictions for 'UP'\n",
    "top_20_up = results.sort_values('prob_up', ascending=False).head(20)\n",
    "print(top_20_up[['ticker', 'prob_up', 'headline']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "e8dccc45-b712-460d-89e4-077253cc67c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test rows from the selected week: 32\n"
     ]
    }
   ],
   "source": [
    "# Find top 10 likeliest stocks to go up in a given week\n",
    "# Step 1: set target week\n",
    "target_open_date = pd.to_datetime(\"2016-09-19\")\n",
    "week_data = merged[merged['open_date_used'] == target_open_date]\n",
    "\n",
    "# Step 2: Get the subset of test data from merged that matches this latest date\n",
    "# Filter merged rows that are both in the test set and match the latest date\n",
    "target_open_mask = (merged['open_date_used'] == target_open_date)\n",
    "target_open_test_mask = target_open_mask & merged.index.isin(test_idx)\n",
    "\n",
    "# Step 3: Get the indices for these filtered rows\n",
    "target_open_test_indices = merged[target_open_test_mask].index\n",
    "\n",
    "# Safety check\n",
    "print(f\"Number of test rows from the selected week: {len(target_open_test_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "1cd19782-1f22-4844-975c-d6bb30dfb05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For open date of:  2016-09-19 00:00:00\n",
      "   ticker   prob_up                                           headline\n",
      "20     EW  0.945389               cramers 11 stock buy fedfear selloff\n",
      "18    IVZ  0.742911            invesco report aug 31st aum 11 mom 821b\n",
      "30    EOG  0.676000  fbr capital initiate coverage eog resource out...\n",
      "28    ADS  0.663000  alliance data report 23 increase yoy receivabl...\n",
      "26    ALL  0.631267     allstate report catastrophe loss aug 2016 154m\n",
      "14    KSU  0.614000  morgan stanley share highlight freight confere...\n",
      "2     OXY  0.585564  benzingas top downgrade jp morgan downgrade oc...\n",
      "22    MYL  0.584702  house oversight committee hold sept 21 hearing...\n",
      "16    NRG  0.562000  watch 7 huge call purchase thursday trade opti...\n",
      "19     XL  0.559832  benzingas top downgrade janney capital downgra...\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Get positional indices within X_test\n",
    "position_in_test = [i for i, idx in enumerate(test_idx) if idx in target_open_test_indices]\n",
    "\n",
    "# Step 5: Subset X_test and get predicted probabilities\n",
    "X_test_latest = X_test[position_in_test]\n",
    "y_prob_latest = clf.predict_proba(X_test_latest)\n",
    "up_probabilities_latest = y_prob_latest[:, 1]\n",
    "\n",
    "# Step 6: Prepare the merged DataFrame slice for matching rows\n",
    "merged_latest_test = merged.loc[test_idx].iloc[position_in_test]\n",
    "\n",
    "# Step 7: Create results DataFrame and display top 10 'UP' predictions\n",
    "results_latest = pd.DataFrame({\n",
    "    'ticker': merged_latest_test['ticker'].values,\n",
    "    'prob_up': up_probabilities_latest,\n",
    "    'true_label': y_test.iloc[position_in_test].values,\n",
    "    'headline': merged_latest_test['weekly_headlines_clean'].values\n",
    "})\n",
    "\n",
    "top_10_up = results_latest.sort_values('prob_up', ascending=False).head(10)\n",
    "print('For open date of: ', target_open_date)\n",
    "print(top_10_up[['ticker', 'prob_up', 'headline']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "4418acc1-a062-4ce1-a0e1-ae32b68111db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ticker   prob_up  friday_close  monday_open  price_change  pct_change  \\\n",
      "0     EW  0.945389    116.599998   116.620003      0.020005    0.017157   \n",
      "1    IVZ  0.742911     30.180000    30.400000      0.220000    0.728960   \n",
      "2    EOG  0.676000     90.970001    91.660004      0.690003    0.758495   \n",
      "3    ADS  0.663000    214.479996   215.759995      1.279999    0.596792   \n",
      "4    ALL  0.631267     67.410004    67.580002      0.169998    0.252185   \n",
      "5    KSU  0.614000     91.070000    91.760002      0.690002    0.757661   \n",
      "6    OXY  0.585564     71.029999    71.529999      0.500000    0.703928   \n",
      "7    MYL  0.584702     41.790001    41.970001      0.180000    0.430725   \n",
      "8    NRG  0.562000     11.260000    11.270000      0.010000    0.088810   \n",
      "9     XL  0.559832     33.450001    33.540001      0.090000    0.269058   \n",
      "\n",
      "                                            headline  \n",
      "0               cramers 11 stock buy fedfear selloff  \n",
      "1            invesco report aug 31st aum 11 mom 821b  \n",
      "2  fbr capital initiate coverage eog resource out...  \n",
      "3  alliance data report 23 increase yoy receivabl...  \n",
      "4     allstate report catastrophe loss aug 2016 154m  \n",
      "5  morgan stanley share highlight freight confere...  \n",
      "6  benzingas top downgrade jp morgan downgrade oc...  \n",
      "7  house oversight committee hold sept 21 hearing...  \n",
      "8  watch 7 huge call purchase thursday trade opti...  \n",
      "9  benzingas top downgrade janney capital downgra...  \n"
     ]
    }
   ],
   "source": [
    "# model performance\n",
    "\n",
    "# find previous friday close and monday open prices for target open date\n",
    "friday_before = target_open_date - timedelta(days=3)\n",
    "tickers_of_interest = top_10_up['ticker'].unique()\n",
    "\n",
    "friday_prices = prices_df[\n",
    "    (prices_df['ticker'].isin(tickers_of_interest)) &\n",
    "    (prices_df['date'] == friday_before)\n",
    "][['ticker', 'close']].rename(columns={'close': 'friday_close'})\n",
    "\n",
    "monday_open_prices = prices_df[\n",
    "    (prices_df['ticker'].isin(tickers_of_interest)) &\n",
    "    (prices_df['date'] == target_open_date)\n",
    "][['ticker', 'open']].rename(columns={'open': 'monday_open'})\n",
    "\n",
    "# merge both prices into top_10_up\n",
    "top_10_enriched = top_10_up.merge(friday_prices, on='ticker', how='left')\n",
    "top_10_enriched = top_10_enriched.merge(monday_open_prices, on='ticker', how='left')\n",
    "\n",
    "# 8. Compute the price change (absolute and percentage)\n",
    "top_10_enriched['price_change'] = top_10_enriched['monday_open'] - top_10_enriched['friday_close']\n",
    "top_10_enriched['pct_change'] = (top_10_enriched['price_change'] / top_10_enriched['friday_close']) * 100\n",
    "\n",
    "# 9. Display the final result\n",
    "print(top_10_enriched[['ticker', 'prob_up', 'friday_close', 'monday_open', 'price_change', 'pct_change', 'headline']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71667660-9d48-42b7-93cb-1e69a873fbac",
   "metadata": {},
   "source": [
    "## Including Weekly Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4eb5efa9-eaf6-4685-9f31-6a3b0532c1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute daily returns\n",
    "prices_df.sort_values(by=['ticker', 'date'], inplace=True)\n",
    "prices_df['daily_return'] = prices_df.groupby('ticker')['close'].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "207cc192-44c8-446e-888e-45d443f1b80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add week of column to allow grouping by ticker and week\n",
    "prices_df['week'] = prices_df['date'].dt.to_period('W').apply(lambda r: r.start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19e23831-85dc-4d65-a7b0-102da8b20dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute weekly volatility\n",
    "weekly_volatility = prices_df.groupby(['ticker', 'week'])['daily_return'].std().reset_index()\n",
    "weekly_volatility.rename(columns={'daily_return': 'weekly_volatility'}, inplace=True)\n",
    "\n",
    "# lag weekly volatility to use the previous week's volatility\n",
    "weekly_volatility['previous_week'] = weekly_volatility.groupby('ticker')['weekly_volatility'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b12899e-f00a-4d44-893a-f9647d21dd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge weekly volatility into previously merged data\n",
    "merged['week'] = merged['monday'].dt.to_period('W').apply(lambda r: r.start_time)\n",
    "merged = pd.merge(merged, weekly_volatility[['ticker', 'week', 'previous_week']], \n",
    "                  on=['ticker', 'week'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b81581e6-354a-4ba9-8964-4ac2ac7c2142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize volatility\n",
    "# Drop rows with missing volatility\n",
    "merged_model = merged.dropna(subset=['previous_week']).copy()\n",
    "\n",
    "# Create a scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the 'previous_week' column\n",
    "merged_model['volatility_scaled'] = scaler.fit_transform(\n",
    "    merged_model[['previous_week']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f3a1c6b1-0fea-4767-a617-5153c993aa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate TF-IDF matrix with volatility feature\n",
    "X_text = tfidf.fit_transform(merged_model['weekly_headlines_clean'])\n",
    "\n",
    "volatility_sparse = sparse.csr_matrix(\n",
    "    merged_model['volatility_scaled'].values.reshape(-1, 1)\n",
    ")\n",
    "\n",
    "# Combine text features and volatility\n",
    "X = hstack([X_text, volatility_sparse])\n",
    "y = merged_model['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c95f5208-7e5a-4c36-9528-117c6457dcdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Time required to train model (sec): 282.9\n"
     ]
    }
   ],
   "source": [
    "# initialize and train the classifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "svm_clf = SVC(kernel='linear')\n",
    "\n",
    "# Train model\n",
    "print(\"Training model...\")\n",
    "start = time.time()\n",
    "svm_clf.fit(X_train, y_train)\n",
    "train_time = time.time() - start\n",
    "print('Time required to train model (sec): {:.1f}'.format(train_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e429c1a4-886c-4e91-812e-a1dee8405375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "      DOWN    UP\n",
      "DOWN  3884  2840\n",
      "UP    3303  3384\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DOWN       0.54      0.58      0.56      6724\n",
      "          UP       0.54      0.51      0.52      6687\n",
      "\n",
      "    accuracy                           0.54     13411\n",
      "   macro avg       0.54      0.54      0.54     13411\n",
      "weighted avg       0.54      0.54      0.54     13411\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = svm_clf.predict(X_test)\n",
    "\n",
    "# confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "labels = sorted(y.unique())\n",
    "cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "print(cm_df)\n",
    "\n",
    "# classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "574f2f4f-602a-4926-8543-23a07f35e12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time required to train model (sec): 2.9\n"
     ]
    }
   ],
   "source": [
    "# try xgboost\n",
    "y = merged_model['target'].map({'DOWN': 0, 'UP': 1})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Define model\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "train_time = time.time() - start\n",
    "print('Time required to train model (sec): {:.1f}'.format(train_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e11f4ad0-92fb-4ffe-a421-0a796a068eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "      0     1\n",
      "0  4527  2197\n",
      "1  4008  2679\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.67      0.59      6724\n",
      "           1       0.55      0.40      0.46      6687\n",
      "\n",
      "    accuracy                           0.54     13411\n",
      "   macro avg       0.54      0.54      0.53     13411\n",
      "weighted avg       0.54      0.54      0.53     13411\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb_clf.predict(X_test)\n",
    "\n",
    "# confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "labels = sorted(y.unique())\n",
    "cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "print(cm_df)\n",
    "\n",
    "# classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c0f06a3b-e26f-445b-8bdc-f054b30ac8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full vocabulary size: 57105\n"
     ]
    }
   ],
   "source": [
    "vectorizer_full = TfidfVectorizer()\n",
    "vectorizer_full.fit(merged['weekly_headlines_clean'])\n",
    "print(\"Full vocabulary size:\", len(vectorizer_full.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "004702cb-e05b-41d1-9c36-eab682d5a7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features=500, Accuracy=0.5576, Train time=49.48\n",
      "max_features=1000, Accuracy=0.5650, Train time=52.80\n",
      "max_features=5000, Accuracy=0.5720, Train time=60.82\n",
      "max_features=None, Accuracy=0.5720, Train time=357.87\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for max_feat in [500, 1000, 5000, None]:\n",
    "    start = time.time()\n",
    "    \n",
    "    tfidf = TfidfVectorizer(max_features=max_feat)\n",
    "    X_text = tfidf.fit_transform(merged['weekly_headlines_clean'])\n",
    "    y = merged['target']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_text, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    train_time = time.time() - start\n",
    "    print(f\"max_features={max_feat}, Accuracy={score:.4f}, Train time={train_time:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ed66cbf5-2bd3-4a10-8a09-3c4faad5f23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 100 | Accuracy: 0.5720 | Train time: 62.13\n",
      "n_estimators: 200 | Accuracy: 0.5742 | Train time: 123.55\n",
      "n_estimators: 500 | Accuracy: 0.5749 | Train time: 316.46\n",
      "n_estimators: 1000 | Accuracy: 0.5771 | Train time: 647.61\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X_text = tfidf.fit_transform(merged['weekly_headlines_clean'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_text, y, test_size=0.2, random_state=42)\n",
    "\n",
    "for n in [100, 200, 500, 1000]:\n",
    "    start = time.time()\n",
    "    clf = RandomForestClassifier(n_estimators=n, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    preds = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    train_time = time.time() - start\n",
    "    print(f\"n_estimators: {n} | Accuracy: {acc:.4f} | Train time: {train_time:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e48134db-63ec-4c28-996a-2308b468e042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5463 |Train time: 0.18\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3690 3026]\n",
      " [3059 3637]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        DOWN       0.55      0.55      0.55      6716\n",
      "          UP       0.55      0.54      0.54      6696\n",
      "\n",
      "    accuracy                           0.55     13412\n",
      "   macro avg       0.55      0.55      0.55     13412\n",
      "weighted avg       0.55      0.55      0.55     13412\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Initialize model\n",
    "log_reg = LogisticRegression(max_iter=2000, random_state=42)\n",
    "\n",
    "# Fit model\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "train_time = time.time() - start\n",
    "\n",
    "# Evaluate\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc:.4f} |Train time: {train_time:.2f}\")\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f750744a-daa9-4780-ad9b-1acf585b532e",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "0ba65dac-c869-47e8-bae6-7d2fb7e727b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "79a63aa4-5f24-4c84-b956-feb9fe86d8ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_34\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_34\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_100 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">640,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_101 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_102 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_100 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m640,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_62 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_101 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_63 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_102 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">648,449</span> (2.47 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m648,449\u001b[0m (2.47 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">648,449</span> (2.47 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m648,449\u001b[0m (2.47 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build model\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),  # Explicit input layer\n",
    "    Dense(128,activation='relu'),\n",
    "    Dropout(0.6),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "40060b2d-62d6-4c4c-b378-9dde7e0d1c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# Early stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "a2299c93-e794-4da9-aea7-90c1396ff8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5106 - loss: 0.6926 - val_accuracy: 0.5391 - val_loss: 0.6887\n",
      "Epoch 2/10\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5933 - loss: 0.6735 - val_accuracy: 0.5505 - val_loss: 0.6857\n",
      "Epoch 3/10\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6379 - loss: 0.6386 - val_accuracy: 0.5553 - val_loss: 0.6942\n",
      "Epoch 4/10\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6879 - loss: 0.5940 - val_accuracy: 0.5526 - val_loss: 0.7163\n",
      "Epoch 5/10\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7261 - loss: 0.5472 - val_accuracy: 0.5559 - val_loss: 0.7385\n",
      "Epoch 6/10\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7726 - loss: 0.4843 - val_accuracy: 0.5569 - val_loss: 0.7731\n",
      "Epoch 7/10\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8058 - loss: 0.4304 - val_accuracy: 0.5538 - val_loss: 0.8067\n",
      "Epoch 8/10\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8307 - loss: 0.3812 - val_accuracy: 0.5553 - val_loss: 0.8523\n",
      "Epoch 9/10\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8498 - loss: 0.3418 - val_accuracy: 0.5580 - val_loss: 0.8905\n",
      "Epoch 10/10\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8663 - loss: 0.3124 - val_accuracy: 0.5594 - val_loss: 0.9342\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step\n",
      "Accuracy: 0.5660 |Train time: 11.84\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3788 2928]\n",
      " [2893 3803]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.56      0.57      6716\n",
      "           1       0.56      0.57      0.57      6696\n",
      "\n",
      "    accuracy                           0.57     13412\n",
      "   macro avg       0.57      0.57      0.57     13412\n",
      "weighted avg       0.57      0.57      0.57     13412\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X_text = tfidf.fit_transform(merged['weekly_headlines_clean'])\n",
    "y = merged['target'].map({'DOWN': 0, 'UP': 1})  # Ensure numeric target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_text, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_dense = X_train.toarray().astype('float32')\n",
    "X_test_dense = X_test.toarray().astype('float32')\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    X_train.toarray(), y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=10,\n",
    "    batch_size=256,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_nn = (model.predict(X_test.toarray()) > 0.5).astype(\"int32\")\n",
    "acc = accuracy_score(y_test, y_pred_nn)\n",
    "\n",
    "train_time = time.time() - start\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f} |Train time: {train_time:.2f}\")\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_nn))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "aa6ef56d-e82b-4da2-b8ce-61c68fb933ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(\n",
    "    figsize=(8,5), xlim=[0, 10], ylim=[0, 1], grid=True, xlabel='Epoch',\n",
    "    style=['r--', 'r--.', 'b-', 'b-*'])\n",
    "plt.title('Learning Curves: 2 Hidden Layers, 128/64 Neurons')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f304d648-bbe7-4cd8-9aa1-c41072e571af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute 52-week moving average and percent undervalued/overvalued\n",
    "\n",
    "# 52-week (approx. 252 trading days) moving average\n",
    "prices_df['52wk_ma'] = prices_df.groupby('ticker')['close'].transform(lambda x: x.rolling(window=252, min_periods=20).mean())\n",
    "\n",
    "# Create new feature: percent_diff_from_52wk_avg = (close - 52wk_ma) / 52wk_ma\n",
    "prices_df['percent_from_52wk_avg'] = (prices_df['close'] - prices_df['52wk_ma']) / prices_df['52wk_ma']\n",
    "\n",
    "# Get previous Friday's close for each open_date_used\n",
    "merged['prev_friday'] = pd.to_datetime(merged['open_date_used']) - pd.to_timedelta(pd.to_datetime(merged['open_date_used']).dt.weekday + 3, unit='D')\n",
    "merged = merged.merge(\n",
    "    prices_df[['ticker', 'date', 'percent_from_52wk_avg']],\n",
    "    left_on=['ticker', 'prev_friday'],\n",
    "    right_on=['ticker', 'date'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Clean up merged dataframe\n",
    "merged = merged.rename(columns={'percent_from_52wk_avg': 'valuation_feature'})\n",
    "merged.drop(columns=['date'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c05822",
   "metadata": {},
   "source": [
    "### Repeat Random Forest Classifier training using daily headline data\n",
    "\n",
    "Create a new `merged_1day` dataframe that contains each trading day's close, the previous day's close, and the previous day's headlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cd202b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize dates to remove time & timezone info\n",
    "news_1day = news_df.copy()\n",
    "news_1day['date'] = pd.to_datetime(news_1day['date'], utc=True)\n",
    "news_1day['date'] = news_1day['date'].dt.tz_localize(None).dt.normalize()\n",
    "\n",
    "# ensure price dates are also normalized\n",
    "prices_df['date'] = pd.to_datetime(prices_df['date'])\n",
    "prices_df['date'] = prices_df['date'].dt.normalize()\n",
    "\n",
    "# limit news to same range as prices\n",
    "min_price_date = prices_df['date'].min()\n",
    "max_price_date = prices_df['date'].max()\n",
    "\n",
    "news_1day = news_1day[\n",
    "    (news_1day['date'] >= min_price_date) &\n",
    "    (news_1day['date'] <= max_price_date)\n",
    "]\n",
    "\n",
    "# get previous trading day per ticker\n",
    "# sort and shift to get the previous trading day for each ticker\n",
    "prices_1day = prices_df[['ticker', 'date', 'close']].copy()\n",
    "prices_1day = prices_1day.sort_values(['ticker', 'date'])\n",
    "prices_1day['prev_trading_date'] = prices_1day.groupby('ticker')['date'].shift(1)\n",
    "\n",
    "# merge with news from the previous trading day\n",
    "merged_with_news = pd.merge(\n",
    "    prices_1day,\n",
    "    news_1day[['ticker', 'date', 'headline']],\n",
    "    left_on=['ticker', 'prev_trading_date'],\n",
    "    right_on=['ticker', 'date'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# rename to avoid confusion\n",
    "news_with_price = merged_with_news.rename(columns={\n",
    "    'date_x': 'date',            # trading date\n",
    "    'date_y': 'headline_date'    # date of the news\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b1d0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate headlines per (ticker, trading day)\n",
    "headline_agg = news_with_price.groupby(['ticker', 'date'])['headline'] \\\n",
    "    .apply(lambda x: \" \".join(x.dropna())).reset_index()\n",
    "\n",
    "# merge aggregated headlines back with prices_1day\n",
    "merged_1day = pd.merge(\n",
    "    prices_1day,\n",
    "    headline_agg,\n",
    "    on=['ticker', 'date'],\n",
    "    how='left'\n",
    ").rename(columns={'headline': 'headlines_prev_day'})\n",
    "\n",
    "# add target column: UP or DOWN\n",
    "# get previous day close for each ticker\n",
    "merged_1day = merged_1day.sort_values(['ticker', 'date'])\n",
    "merged_1day['prev_close'] = merged_1day.groupby('ticker')['close'].shift(1)\n",
    "\n",
    "# create target column\n",
    "merged_1day['target'] = np.where(\n",
    "    merged_1day['close'] > merged_1day['prev_close'],\n",
    "    'UP', 'DOWN'\n",
    ")\n",
    "\n",
    "# reorder columns for clarity\n",
    "merged_1day = merged_1day[['ticker', 'date', 'prev_trading_date', 'prev_close', 'headlines_prev_day', 'close', 'target']]\n",
    "\n",
    "# drop rows without headlines\n",
    "merged_1day = merged_1day[\n",
    "    merged_1day['headlines_prev_day'].fillna('').str.strip() != ''\n",
    "]\n",
    "\n",
    "# reset index\n",
    "merged_1day.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a405458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean and lemmatize headlines\n",
    "merged_1day['headlines_prev_day_clean'] = merged_1day['headlines_prev_day'].apply(clean)\n",
    "\n",
    "merged_1day.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea345d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize cleaned 1 day headlines\n",
    "print(\"Vectorizing text...\")\n",
    "tfidf = TfidfVectorizer(max_features=5000) \n",
    "X_text_1d = tfidf.fit_transform(merged_1day['headlines_prev_day_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01a3be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train randomforest classifier and measure train time\n",
    "start = time.time()\n",
    "\n",
    "X_1d = X_text_1d\n",
    "y_1d = merged_1day['target']\n",
    "\n",
    "# Save original indices\n",
    "original_indices_1d = merged_1day.index\n",
    "\n",
    "X_train, X_test, y_train, y_test, train_idx, test_idx = train_test_split(\n",
    "    X_1d, y_1d, original_indices_1d, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training model...\")\n",
    "clf_1d = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "clf_1d.fit(X_train, y_train)\n",
    "\n",
    "train_time = time.time() - start\n",
    "print('Time required to train model (sec): {:.1f}'.format(train_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef51499a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_1d.predict(X_test)\n",
    "\n",
    "# confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "labels = sorted(y.unique())\n",
    "cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "print(cm_df)\n",
    "\n",
    "# classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12862cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predicted probabilities of going 'UP'\n",
    "y_proba = clf_1d.predict_proba(X_test)\n",
    "proba_up = y_proba[:, 1]\n",
    "\n",
    "# create dataframe to assess top predictions\n",
    "results = pd.DataFrame({\n",
    "    'ticker': merged_1day.loc[test_idx, 'ticker'].values,\n",
    "    'prob_up': proba_up,\n",
    "    'true_label': y_test,\n",
    "    'headline': merged_1day.loc[test_idx, 'headlines_prev_day_clean'].values\n",
    "})\n",
    "\n",
    "# find top 20 most confident predictions for 'UP'\n",
    "top_20_up = results.sort_values('prob_up', ascending=False).head(20)\n",
    "print(top_20_up[['ticker', 'true_label', 'prob_up', 'headline']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af51a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find top 10 likeliest stocks to go up on a given day\n",
    "\n",
    "# Step 1: set target day\n",
    "target_day = pd.to_datetime(\"2016-09-06\")\n",
    "target_day_data = merged_1day[merged_1day['date'] == target_day]\n",
    "\n",
    "# Step 2: Get the subset of test data from merged that matches this latest date\n",
    "# Filter merged rows that are both in the test set and match the latest date\n",
    "target_day_test_mask = target_day_data.index.isin(test_idx)\n",
    "target_day_test = target_day_data[target_day_test_mask]\n",
    "\n",
    "# Step 4: Get predictions for those test rows\n",
    "X_target = tfidf.transform(target_day_test['headlines_prev_day'])\n",
    "pred_probs = clf_1d.predict_proba(X_target)  # Assuming binary classification with 'DOWN' and 'UP'\n",
    "up_probs = pred_probs[:, list(clf_1d.classes_).index('UP')]  # Probabilities of going UP\n",
    "\n",
    "# Step 5: Add predictions back to the test DataFrame\n",
    "target_day_test = target_day_test.copy()\n",
    "target_day_test['prob_up'] = up_probs\n",
    "\n",
    "# Step 6: Sort by probability of going up and select top 10\n",
    "top_10 = target_day_test.sort_values('prob_up', ascending=False).head(10)\n",
    "\n",
    "# Display the top 10 likeliest stocks to go up on that trading day\n",
    "print(top_10[['ticker', 'date', 'prob_up']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcd749e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assess predictive performance\n",
    "\n",
    "# Make a copy of the top_10 predictions\n",
    "top_10_eval = top_10.copy()\n",
    "\n",
    "# Calculate absolute price change\n",
    "top_10_eval['abs_price_change'] = (top_10_eval['close'] - top_10_eval['prev_close'])\n",
    "\n",
    "# Calculate percentage change\n",
    "top_10_eval['pct_price_change'] = ((top_10_eval['close'] - top_10_eval['prev_close']) / top_10_eval['prev_close']) * 100\n",
    "\n",
    "# Display relevant columns\n",
    "print(top_10_eval[['ticker', 'date', 'prev_close', 'close', 'abs_price_change', 'pct_price_change', 'prob_up']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29776fba",
   "metadata": {},
   "source": [
    "## Back testing: assess model performance over time\n",
    "\n",
    "For each day, select the top 5 model-predicted stocks, calculate the average return across the 5 picks for that day, and cumulatively sum the daily average returns. Finally compare the cumulative returns to the S&P 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81933a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame of test predictions\n",
    "test_preds_df = pd.DataFrame({\n",
    "    'index': test_idx,\n",
    "    'prob_up': proba_up\n",
    "})\n",
    "\n",
    "# merge predictions with test subset of merged_1day\n",
    "# Reset index to allow merge on 'index'\n",
    "merged_test = merged_1day.reset_index().merge(test_preds_df, on='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f61aa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add % return column\n",
    "merged_test['daily_return_pct'] = ((merged_test['close'] - merged_test['prev_close']) / merged_test['prev_close']) * 100\n",
    "\n",
    "# sort by date and prob_up\n",
    "sorted_preds = merged_test.sort_values(by=['date', 'prob_up'], ascending=[True, False])\n",
    "\n",
    "# get top 5 picks per day\n",
    "top5_daily = sorted_preds.groupby('date').head(5)\n",
    "\n",
    "# calculate average return for top 5 picks per day\n",
    "daily_avg_return = top5_daily.groupby('date')['daily_return_pct'].mean().reset_index()\n",
    "daily_avg_return.rename(columns={'daily_return_pct': 'avg_top5_return_pct'}, inplace=True)\n",
    "\n",
    "# compute cumulative return over time (compounded)\n",
    "daily_avg_return['cumulative_return_pct'] = (1 + daily_avg_return['avg_top5_return_pct'] / 100).cumprod() - 1\n",
    "daily_avg_return['cumulative_return_pct'] *= 100  # back to percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f56ea99",
   "metadata": {},
   "outputs": [],
   "source": [
    " # compare to S&P 500\n",
    "import yfinance as yf\n",
    "\n",
    "# get S&P 500 data for the same date range\n",
    "start_date = daily_avg_return['date'].min()\n",
    "end_date = daily_avg_return['date'].max()\n",
    "sp500 = yf.download(\"^GSPC\", start=start_date, end=end_date)\n",
    "\n",
    "# ensure index is datetime and trimmed to match your data\n",
    "sp500 = sp500[['Open', 'Close']]\n",
    "sp500 = sp500.reset_index()  # brings 'Date' into a column\n",
    "sp500.rename(columns={'Date': 'date'}, inplace=True)  # match column name with daily_avg_return\n",
    "\n",
    "# prepare the S&P 500 daily % returns and cumulative return\n",
    "sp500['daily_return_pct'] = ((sp500['Close'] - sp500['Open']) / sp500['Open']) * 100\n",
    "sp500['sp500_cum_return_pct'] = (1 + sp500['daily_return_pct'] / 100).cumprod() - 1\n",
    "sp500['sp500_cum_return_pct'] *= 100\n",
    "\n",
    "# ensure both DataFrames have 'date' as a column and flat index\n",
    "daily_avg_return = daily_avg_return.reset_index(drop=True)\n",
    "sp500 = sp500.reset_index(drop=True)\n",
    "\n",
    "# double-check 'date' is datetime type\n",
    "daily_avg_return['date'] = pd.to_datetime(daily_avg_return['date'])\n",
    "sp500['date'] = pd.to_datetime(sp500['date'])\n",
    "\n",
    "# flatten all multi-level columns (if any)\n",
    "daily_avg_return.columns = [col if isinstance(col, str) else col[0] for col in daily_avg_return.columns]\n",
    "sp500.columns = [col if isinstance(col, str) else col[0] for col in sp500.columns]\n",
    "\n",
    "# merge with your model returns\n",
    "comparison_df = daily_avg_return.merge(\n",
    "    sp500[['date', 'sp500_cum_return_pct']],\n",
    "    on='date',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b665021",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# plot model returns and S&P 500 returns\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(comparison_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m], comparison_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcumulative_return_pct\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel Top 5 Picks\u001b[39m\u001b[38;5;124m'\u001b[39m, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(comparison_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m], comparison_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msp500_cum_return_pct\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS&P 500\u001b[39m\u001b[38;5;124m'\u001b[39m, linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m'\u001b[39m, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# plot model returns and S&P 500 returns\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(comparison_df['date'], comparison_df['cumulative_return_pct'], label='Model Top 5 Picks', marker='o')\n",
    "plt.plot(comparison_df['date'], comparison_df['sp500_cum_return_pct'], label='S&P 500', linestyle='--', marker='x')\n",
    "\n",
    "plt.title(\"Cumulative Return: Model vs S&P 500\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Cumulative Return (%)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d787ab3",
   "metadata": {},
   "source": [
    "# Update all models: Train-Test to Split on Dates Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e71d1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_1day.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f654862",
   "metadata": {},
   "source": [
    "### Train-Val-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e469dff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data into train (60%), val (20%), and test (20%) sets\n",
    "\n",
    "# get unique dates\n",
    "unique_dates = merged_1day['date'].unique()\n",
    "\n",
    "# split the dates into (train+val) and test\n",
    "trainval_dates, test_dates = train_test_split(\n",
    "    unique_dates, test_size=0.2, random_state=42)\n",
    "\n",
    "# split trainval_dates into train and validation sets:\n",
    "train_dates, val_dates = train_test_split(\n",
    "    trainval_dates, test_size=0.25, random_state=42)\n",
    "\n",
    "merged_1day_train = merged_1day[merged_1day['date'].isin(train_dates)]\n",
    "merged_1day_val = merged_1day[merged_1day['date'].isin(val_dates)]\n",
    "merged_1day_test = merged_1day[merged_1day['date'].isin(test_dates)]\n",
    "\n",
    "# preserve indices for retrieval of headline and price data after model evaluation\n",
    "train_indices = merged_1day_train.index\n",
    "val_indices = merged_1day_val.index\n",
    "test_indices = merged_1day_test.index\n",
    "\n",
    "# separate X and y\n",
    "X_train = merged_1day_train['headlines_prev_day_clean']\n",
    "X_val = merged_1day_val['headlines_prev_day_clean']\n",
    "X_test = merged_1day_test['headlines_prev_day_clean']\n",
    "y_train = merged_1day_train['target'].map({'DOWN': 0, 'UP': 1}).astype(int)\n",
    "y_val = merged_1day_val['target'].map({'DOWN': 0, 'UP': 1}).astype(int)\n",
    "y_test = merged_1day_test['target'].map({'DOWN': 0, 'UP': 1}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e6fd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify the split sizes and confirm no overlapping dates\n",
    "\n",
    "# size of original data\n",
    "total_size = len(merged_1day)\n",
    "\n",
    "# sizes of the splits\n",
    "train_size = len(X_train)\n",
    "val_size = len(X_val)\n",
    "test_size = len(X_test)\n",
    "\n",
    "# Fractions\n",
    "print(f\"Train fraction: {train_size / total_size:.3f}\")\n",
    "print(f\"Validation fraction: {val_size / total_size:.3f}\")\n",
    "print(f\"Test fraction: {test_size / total_size:.3f}\")\n",
    "print(f\"Total fraction: {(train_size + val_size + test_size) / total_size:.3f}\")\n",
    "print()\n",
    "\n",
    "# collect dates in each set\n",
    "dates_train = merged_1day.loc[X_train.index, 'date']\n",
    "dates_val = merged_1day.loc[X_val.index, 'date']\n",
    "dates_test = merged_1day.loc[X_test.index, 'date']\n",
    "\n",
    "# convert to sets\n",
    "set_train_dates = set(dates_train)\n",
    "set_val_dates = set(dates_val)\n",
    "set_test_dates = set(dates_test)\n",
    "\n",
    "# check overlaps\n",
    "train_val_overlap = set_train_dates.intersection(set_val_dates)\n",
    "train_test_overlap = set_train_dates.intersection(set_test_dates)\n",
    "val_test_overlap = set_val_dates.intersection(set_test_dates)\n",
    "\n",
    "# Print results\n",
    "print(f\"Overlap between train and val dates: {len(train_val_overlap)}\")\n",
    "print(f\"Overlap between train and test dates: {len(train_test_overlap)}\")\n",
    "print(f\"Overlap between val and test dates: {len(val_test_overlap)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcea0d78",
   "metadata": {},
   "source": [
    "### Build and Tune Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7567224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build pipeline\n",
    "rf_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('rf', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# parameter grid to search\n",
    "param_grid = {\n",
    "    'tfidf__max_features': [5000, 10000],\n",
    "    'rf__n_estimators': [200, 400],\n",
    "    'rf__max_depth': [None]\n",
    "}\n",
    "\n",
    "# stratified KFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# GridSearch\n",
    "rf_grid = GridSearchCV(\n",
    "    rf_pipeline,\n",
    "    param_grid,\n",
    "    cv=skf,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44150f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time estimates and progress bar for GridSearchCV\n",
    "\n",
    "# progress bar does not work inside jupyter notebook\n",
    "class GridSearchCVProgress(GridSearchCV):\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        n_candidates = len(self.param_grid) if isinstance(self.param_grid, list) else np.prod([len(v) for v in self.param_grid.values()])\n",
    "        n_splits = self.cv if isinstance(self.cv, int) else self.cv.get_n_splits()\n",
    "        total = n_candidates * n_splits\n",
    "        \n",
    "        with tqdm(total=total, desc=\"GridSearchCV Progress\", ncols=100) as pbar:\n",
    "            old_score = self._score\n",
    "        \n",
    "            def _score_with_progress(*args, **kwargs):\n",
    "                pbar.update(1)\n",
    "                return old_score(*args, **kwargs)\n",
    "            \n",
    "            self._score = _score_with_progress\n",
    "            return super().fit(X, y, **fit_params)\n",
    "\n",
    "# estimate time to search\n",
    "sample_frac = 0.05  # 5% sample\n",
    "X_sample = X_train.sample(frac=sample_frac, random_state=42)\n",
    "y_sample = y_train.loc[X_sample.index]\n",
    "\n",
    "# create 1 fold manually\n",
    "train_idx, val_idx = next(iter(skf.split(X_sample, y_sample)))\n",
    "X_fold_train, y_fold_train = X_sample.iloc[train_idx], y_sample.iloc[train_idx]\n",
    "X_fold_val, y_fold_val = X_sample.iloc[val_idx], y_sample.iloc[val_idx]\n",
    "\n",
    "rf_pipeline_clone = clone(rf_pipeline)\n",
    "\n",
    "start = time.time()\n",
    "rf_pipeline_clone.fit(X_fold_train, y_fold_train)\n",
    "_ = rf_pipeline_clone.predict(X_fold_val)\n",
    "time_per_fold_sample = time.time() - start\n",
    "\n",
    "correction_factor = 1 / sample_frac\n",
    "time_per_fold_full = time_per_fold_sample * correction_factor\n",
    "\n",
    "# estimate total time\n",
    "n_candidates = len(param_grid) if isinstance(param_grid, list) else np.prod([len(v) for v in param_grid.values()])\n",
    "n_folds = 5\n",
    "\n",
    "estimated_total_time = time_per_fold_full * n_candidates * n_folds\n",
    "\n",
    "print(f\"Estimated total GridSearchCV time: {estimated_total_time/60:.2f} minutes (~{estimated_total_time/3600:.2f} hours)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ad32d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit on the training set\n",
    "start = time.time()\n",
    "rf_grid.fit(X_train, y_train)\n",
    "train_time = time.time() - start\n",
    "print('Time required to tune model (min): {:.1f}'.format(train_time/60))\n",
    "\n",
    "# best model\n",
    "print(f\"Best RF Parameters: {rf_grid.best_params_}\")\n",
    "print(f\"Best RF CV Accuracy: {rf_grid.best_score_:.4f}\")\n",
    "\n",
    "# get the best pipeline\n",
    "best_rf_model = rf_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c69d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_probs = best_rf_model.predict_proba(X_val)\n",
    "rf_y_proba = rf_probs[:, 1]\n",
    "rf_y_pred = (rf_y_proba > 0.5).astype(\"int32\")\n",
    "rf_acc = accuracy_score(y_val, rf_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c681bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display validation accuracy\n",
    "print(f\"Validation Accuracy: {rf_acc:.4f}\")\n",
    "\n",
    "# confusion matrix\n",
    "rf_cm = confusion_matrix(y_val, rf_y_pred)\n",
    "labels = sorted(merged_1day['target'].unique())\n",
    "rf_cm_df = pd.DataFrame(rf_cm, index=labels, columns=labels)\n",
    "\n",
    "# classification report\n",
    "rf_cr = classification_report(y_val, rf_y_pred, output_dict=True)\n",
    "rf_cr_df = pd.DataFrame(rf_cr).transpose()\n",
    "for col in ['precision', 'recall', 'f1-score']:\n",
    "    rf_cr_df[col] = rf_cr_df[col].round(3)\n",
    "rf_cr_df['support'] = rf_cr_df['support'].astype(int)\n",
    "rf_cr_df.rename(index={'0': 'DOWN', '1': 'UP'}, inplace=True)\n",
    "\n",
    "# plot confusion matrix and classification report\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# confusion matrix on left\n",
    "axes[0].axis('off')\n",
    "table1 = axes[0].table(cellText=rf_cm_df.values,\n",
    "                       rowLabels=rf_cm_df.index,\n",
    "                       colLabels=rf_cm_df.columns,\n",
    "                       cellLoc='center',\n",
    "                       loc='center',\n",
    "                       rowLoc='center',\n",
    "                       colLoc='center',\n",
    "                       colWidths=[0.2]*len(rf_cm_df.columns)\n",
    ")\n",
    "\n",
    "table1.auto_set_font_size(False)\n",
    "table1.set_fontsize(18)\n",
    "table1.scale(1.2, 2.0)\n",
    "for key, cell in table1.get_celld().items():\n",
    "    cell.set_linewidth(1.2)\n",
    "    cell.set_edgecolor('gray')\n",
    "axes[0].set_title('Confusion Matrix - Random Forest', fontsize=24, pad=20)\n",
    "\n",
    "# classification report on right\n",
    "axes[1].axis('off')\n",
    "\n",
    "table2 = axes[1].table(cellText=rf_cr_df.values,\n",
    "                       rowLabels=rf_cr_df.index,\n",
    "                       colLabels=rf_cr_df.columns,\n",
    "                       cellLoc='center',\n",
    "                       loc='center',\n",
    "                       rowLoc='center',\n",
    "                       colLoc='center',\n",
    "                       colWidths=[0.2]*len(rf_cr_df.columns)\n",
    ")\n",
    "\n",
    "table2.auto_set_font_size(False)\n",
    "table2.set_fontsize(16)\n",
    "table2.scale(1.2, 2.0)\n",
    "for key, cell in table2.get_celld().items():\n",
    "    cell.set_linewidth(1.2)\n",
    "    cell.set_edgecolor('gray')\n",
    "axes[1].set_title('Classification Report - Random Forest', fontsize=24, pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('rf_confusion_and_classification_report.png', dpi=300,  bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2540cea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess cumulative returns by picking most likely UPs daily\n",
    "\n",
    "# create copy of merged_1day_val with results\n",
    "rf_val_results = merged_1day_val.copy()\n",
    "rf_val_results['prob_up'] = rf_y_proba\n",
    "\n",
    "# add daily % return column\n",
    "rf_val_results['daily_return_pct'] = ((rf_val_results['close'] - rf_val_results['prev_close']) / rf_val_results['prev_close']) * 100\n",
    "\n",
    "# sort by date and predicted probability\n",
    "rf_sorted_preds = rf_val_results.sort_values(by=['date', 'prob_up'], ascending=[True, False])\n",
    "\n",
    "# apply threshold filter (keep only confident picks)\n",
    "rf_sorted_preds = rf_sorted_preds[rf_sorted_preds['prob_up'] >= 0.6]\n",
    "\n",
    "# get top 5 (or fewer) picks per day\n",
    "rf_top5_daily = rf_sorted_preds.groupby('date').head(5)\n",
    "\n",
    "# calculate average return for the top picks per day\n",
    "rf_daily_avg_return = rf_top5_daily.groupby('date')['daily_return_pct'].mean().reset_index()\n",
    "rf_daily_avg_return.rename(columns={'daily_return_pct': 'avg_top5_return_pct'}, inplace=True)\n",
    "\n",
    "# compute cumulative return (compounded over time)\n",
    "rf_daily_avg_return['cumulative_return_pct'] = (1 + rf_daily_avg_return['avg_top5_return_pct'] / 100).cumprod() - 1\n",
    "rf_daily_avg_return['cumulative_return_pct'] *= 100  # back to percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828f9d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build S&P 500 comparison\n",
    "\n",
    "# get S&P 500 data for the same date range\n",
    "start_date = rf_daily_avg_return['date'].min()\n",
    "end_date = rf_daily_avg_return['date'].max()\n",
    "sp500 = yf.download(\"^GSPC\", start=start_date, end=end_date)\n",
    "\n",
    "# ensure index is datetime and trimmed to match your data\n",
    "sp500 = sp500[['Open', 'Close']]\n",
    "sp500 = sp500.reset_index()  # brings 'Date' into a column\n",
    "sp500.rename(columns={'Date': 'date'}, inplace=True)  # match column name with daily_avg_return\n",
    "\n",
    "# prepare the S&P 500 daily % returns and cumulative return\n",
    "sp500['daily_return_pct'] = ((sp500['Close'] - sp500['Open']) / sp500['Open']) * 100\n",
    "sp500['sp500_cum_return_pct'] = (1 + sp500['daily_return_pct'] / 100).cumprod() - 1\n",
    "sp500['sp500_cum_return_pct'] *= 100\n",
    "\n",
    "# ensure sp500 'date' is datetime type\n",
    "sp500['date'] = pd.to_datetime(sp500['date'])\n",
    "\n",
    "# flatten sp500 multi-level columns (if any)\n",
    "sp500.columns = [col if isinstance(col, str) else col[0] for col in sp500.columns]\n",
    "\n",
    "# merge with your returns\n",
    "rf_comparison = rf_daily_avg_return.merge(\n",
    "    sp500[['date', 'sp500_cum_return_pct']],\n",
    "    on='date',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279a942c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot rf model returns and S&P 500 returns\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(\n",
    "    rf_comparison['date'], rf_comparison['cumulative_return_pct'],\n",
    "    label='Random Forest Model Top 5 Picks',\n",
    "    color='green', marker='s', linestyle='-')\n",
    "plt.plot(\n",
    "    rf_comparison['date'], rf_comparison['sp500_cum_return_pct'],\n",
    "    label='S&P 500',\n",
    "    color='black', marker='x', linestyle='--')\n",
    "\n",
    "plt.title(\"Random Forest Cumulative Return: Model vs S&P 500\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Cumulative Return (%)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('new_rf_cumulative_return_comparison.png', format='png') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62469b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distributions of predictions by true class\n",
    "y_val_array = np.array(y_val)\n",
    "\n",
    "# Then split the predicted probabilities based on true labels\n",
    "probs_positive = rf_probs[y_val_array == 1]\n",
    "probs_negative = rf_probs[y_val_array == 0]\n",
    "\n",
    "probs_positive = probs_positive.flatten()\n",
    "probs_negative = probs_negative.flatten()\n",
    "\n",
    "# Now plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(probs_positive, bins=40, alpha=0.7, label='True Positive (UP)', color='blue', edgecolor='k')\n",
    "plt.hist(probs_negative, bins=40, alpha=0.7, label='True Negative (DOWN)', color='red', edgecolor='k')\n",
    "\n",
    "plt.title('Random Forest Distribution of Predicted Probabilities by True Class')\n",
    "plt.xlabel('Predicted Probability of Positive Class')\n",
    "plt.ylabel('Number of Test Instances')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "#plt.savefig('new_rf_prob_distribution_versus_true_class.png', format='png') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387f1947",
   "metadata": {},
   "source": [
    "### Build and Tune Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c45cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Keras model builder function\n",
    "def build_nn_model(hidden_layer_sizes=(128, 64),\n",
    "                   dropout_rates=(0.6, 0.3),\n",
    "                   activation='relu',\n",
    "                   optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(5000,)))\n",
    "        \n",
    "    model.add(Dense(hidden_layer_sizes[0], activation=activation))\n",
    "    model.add(Dropout(dropout_rates[0]))\n",
    "    \n",
    "    model.add(Dense(hidden_layer_sizes[1], activation=activation))\n",
    "    model.add(Dropout(dropout_rates[1]))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6410e427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build pipeline\n",
    "nn_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=5000)),\n",
    "    ('nn', KerasClassifier(model=build_nn_model, verbose=0))\n",
    "])\n",
    "\n",
    "# parameter grid\n",
    "nn_param_grid = {\n",
    "    'tfidf__max_features': [5000],\n",
    "    'nn__model__activation': ['relu'],\n",
    "    'nn__optimizer': ['adam'],\n",
    "    'nn__batch_size': [32],\n",
    "    'nn__epochs': [10],\n",
    "    'nn__model__dropout_rates': [(0.6, 0.3)]\n",
    "}\n",
    "\n",
    "# GridSearch\n",
    "nn_grid = GridSearchCV(\n",
    "    nn_pipeline, nn_param_grid,\n",
    "    cv=skf,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=1,\n",
    "    verbose=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bb38c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate tuning time\n",
    "nn_pipeline_clone = clone(nn_pipeline)\n",
    "\n",
    "start = time.time()\n",
    "nn_pipeline_clone.fit(X_fold_train, y_fold_train)\n",
    "_ = nn_pipeline_clone.predict(X_fold_val)\n",
    "time_per_fold_sample = time.time() - start\n",
    "\n",
    "correction_factor = 1 / sample_frac\n",
    "time_per_fold_full = time_per_fold_sample * correction_factor\n",
    "\n",
    "# estimate total time\n",
    "n_candidates = len(nn_param_grid) if isinstance(nn_param_grid, list) else np.prod([len(v) for v in nn_param_grid.values()])\n",
    "n_folds = 5\n",
    "\n",
    "estimated_total_time = time_per_fold_full * n_candidates * n_folds\n",
    "\n",
    "print(f\"Estimated total GridSearchCV time: {estimated_total_time/60:.2f} minutes (~{estimated_total_time/3600:.2f} hours)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dc0b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit on the training set\n",
    "start = time.time()\n",
    "nn_grid.fit(X_train, y_train)\n",
    "train_time = time.time() - start\n",
    "print('Time required to tune model (min): {:.1f}'.format(train_time/60))\n",
    "\n",
    "# best model\n",
    "print(f\"Best RF Parameters: {nn_grid.best_params_}\")\n",
    "print(f\"Best RF CV Accuracy: {nn_grid.best_score_:.4f}\")\n",
    "\n",
    "# get the best pipeline\n",
    "best_nn_model = nn_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f061af",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_probs = best_nn_model.predict_proba(X_val)\n",
    "nn_y_proba = nn_probs[:, 1]\n",
    "nn_y_pred = (nn_y_proba > 0.5).astype(\"int32\")\n",
    "nn_acc = accuracy_score(y_val, nn_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7ce896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display validation accuracy\n",
    "print(f\"Validation Accuracy: {nn_acc:.4f}\")\n",
    "\n",
    "# confusion matrix\n",
    "nn_cm = confusion_matrix(y_val, nn_y_pred)\n",
    "labels = sorted(merged_1day['target'].unique())\n",
    "nn_cm_df = pd.DataFrame(nn_cm, index=labels, columns=labels)\n",
    "\n",
    "# classification report\n",
    "nn_cr = classification_report(y_val, nn_y_pred, output_dict=True)\n",
    "nn_cr_df = pd.DataFrame(nn_cr).transpose()\n",
    "for col in ['precision', 'recall', 'f1-score']:\n",
    "    nn_cr_df[col] = nn_cr_df[col].round(4)\n",
    "nn_cr_df['support'] = nn_cr_df['support'].astype(int)\n",
    "nn_cr_df.rename(index={'0': 'DOWN', '1': 'UP'}, inplace=True)\n",
    "\n",
    "# plot confusion matrix and classification report\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# confusion matrix on left\n",
    "axes[0].axis('off')\n",
    "table1 = axes[0].table(cellText=nn_cm_df.values,\n",
    "                       rowLabels=nn_cm_df.index,\n",
    "                       colLabels=nn_cm_df.columns,\n",
    "                       cellLoc='center',\n",
    "                       loc='center',\n",
    "                       rowLoc='center',\n",
    "                       colLoc='center',\n",
    "                       colWidths=[0.2]*len(nn_cm_df.columns)\n",
    ")\n",
    "\n",
    "table1.auto_set_font_size(False)\n",
    "table1.set_fontsize(18)\n",
    "table1.scale(1.2, 2.0)\n",
    "for key, cell in table1.get_celld().items():\n",
    "    cell.set_linewidth(1.2)\n",
    "    cell.set_edgecolor('gray')\n",
    "axes[0].set_title('Confusion Matrix - Neural Network', fontsize=24, pad=20)\n",
    "\n",
    "# classification report on right\n",
    "axes[1].axis('off')\n",
    "\n",
    "table2 = axes[1].table(cellText=nn_cr_df.values,\n",
    "                       rowLabels=nn_cr_df.index,\n",
    "                       colLabels=nn_cr_df.columns,\n",
    "                       cellLoc='center',\n",
    "                       loc='center',\n",
    "                       rowLoc='center',\n",
    "                       colLoc='center',\n",
    "                       colWidths=[0.2]*len(nn_cr_df.columns)\n",
    ")\n",
    "\n",
    "table2.auto_set_font_size(False)\n",
    "table2.set_fontsize(16)\n",
    "table2.scale(1.2, 2.0)\n",
    "for key, cell in table2.get_celld().items():\n",
    "    cell.set_linewidth(1.2)\n",
    "    cell.set_edgecolor('gray')\n",
    "axes[1].set_title('Classification Report - Neural Network', fontsize=24, pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('nn_confusion_and_classification_report.png', dpi=300,  bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896edcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess cumulative returns by picking most likely UPs daily\n",
    "\n",
    "# create copy of merged_1day_val with results\n",
    "nn_val_results = merged_1day_val.copy()\n",
    "nn_val_results['prob_up'] = nn_y_proba\n",
    "\n",
    "# add daily % return column\n",
    "nn_val_results['daily_return_pct'] = ((nn_val_results['close'] - nn_val_results['prev_close']) / nn_val_results['prev_close']) * 100\n",
    "\n",
    "# sort by date and predicted probability\n",
    "nn_sorted_preds = nn_val_results.sort_values(by=['date', 'prob_up'], ascending=[True, False])\n",
    "\n",
    "# apply threshold filter (keep only confident picks)\n",
    "nn_sorted_preds = nn_sorted_preds[nn_sorted_preds['prob_up'] >= 0.6]\n",
    "\n",
    "# get top 5 (or fewer) picks per day\n",
    "nn_top5_daily = nn_sorted_preds.groupby('date').head(5)\n",
    "\n",
    "# calculate average return for the top picks per day\n",
    "nn_daily_avg_return = nn_top5_daily.groupby('date')['daily_return_pct'].mean().reset_index()\n",
    "nn_daily_avg_return.rename(columns={'daily_return_pct': 'avg_top5_return_pct'}, inplace=True)\n",
    "\n",
    "# compute cumulative return (compounded over time)\n",
    "nn_daily_avg_return['cumulative_return_pct'] = (1 + nn_daily_avg_return['avg_top5_return_pct'] / 100).cumprod() - 1\n",
    "nn_daily_avg_return['cumulative_return_pct'] *= 100  # back to percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28121ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with model returns\n",
    "nn_comparison = nn_daily_avg_return.merge(\n",
    "    sp500[['date', 'sp500_cum_return_pct']],\n",
    "    on='date',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37265ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot nn model returns and S&P 500 returns\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(nn_comparison['date'], nn_comparison['cumulative_return_pct'],\n",
    "         label='Neural Network Model Top 5 Picks',\n",
    "         color='red', marker='^', linestyle='-')\n",
    "plt.plot(nn_comparison['date'], nn_comparison['sp500_cum_return_pct'],\n",
    "         label='S&P 500',\n",
    "         color='black', marker='x', linestyle='--')\n",
    "\n",
    "plt.title(\"Neural Network Cumulative Return: Model vs S&P 500\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Cumulative Return (%)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('new_nn_cumulative_return_comparison.png', format='png') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd63e697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distributions of predictions by true class\n",
    "\n",
    "# split the predicted probabilities based on true labels\n",
    "nn_probs_positive = nn_probs[y_val_array == 1]\n",
    "nn_probs_negative = nn_probs[y_val_array == 0]\n",
    "\n",
    "nn_probs_positive = nn_probs_positive.flatten()\n",
    "nn_probs_negative = nn_probs_negative.flatten()\n",
    "\n",
    "# Now plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(nn_probs_positive, bins=40, alpha=0.7, label='True Positive (UP)', color='blue', edgecolor='k')\n",
    "plt.hist(nn_probs_negative, bins=40, alpha=0.7, label='True Negative (DOWN)', color='red', edgecolor='k')\n",
    "\n",
    "plt.title('Neural Network Distribution of Predicted Probabilities by True Class')\n",
    "plt.xlabel('Predicted Probability of Positive Class')\n",
    "plt.ylabel('Number of Test Instances')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "#plt.savefig('new_nn_prob_distribution_versus_true_class.png', format='png') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff98163b",
   "metadata": {},
   "source": [
    "## Build and Train Stacked Model with K-fold Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d95cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge train and val sets\n",
    "X_train_full = pd.concat([X_train, X_val], axis=0)\n",
    "y_train_full = pd.concat([y_train, y_val], axis=0)\n",
    "\n",
    "# prepare base model clones (to avoid leakage)\n",
    "base_model_1 = clone(best_rf_model)\n",
    "base_model_2 = clone(best_nn_model)\n",
    "\n",
    "# initialize out-of-fold prediction arrays\n",
    "n_folds = 5\n",
    "oof_preds_rf = np.zeros(len(X_train_full))\n",
    "oof_preds_nn = np.zeros(len(X_train_full))\n",
    "\n",
    "# loop through folds\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_full, y_train_full)):\n",
    "    print(f\"Training fold {fold + 1}/{n_folds}...\")\n",
    "    \n",
    "    # split data\n",
    "    X_tr, X_val_fold = X_train_full.iloc[train_idx], X_train_full.iloc[val_idx]\n",
    "    y_tr, y_val_fold = y_train_full.iloc[train_idx], y_train_full.iloc[val_idx]\n",
    "    \n",
    "    # train both base models\n",
    "    model_rf = clone(base_model_1)\n",
    "    model_nn = clone(base_model_2)\n",
    "\n",
    "    model_rf.fit(X_tr, y_tr)\n",
    "    model_nn.fit(X_tr, y_tr, nn__verbose=0)\n",
    "\n",
    "    # get validation predictions\n",
    "    oof_preds_rf[val_idx] = model_rf.predict_proba(X_val_fold)[:, 1]\n",
    "    oof_preds_nn[val_idx] = model_nn.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "# stack OOF predictions together\n",
    "stacked_oof_preds = np.column_stack((oof_preds_rf, oof_preds_nn))\n",
    "\n",
    "# train meta-model\n",
    "meta_model = LogisticRegression()\n",
    "meta_model.fit(stacked_oof_preds, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7bbac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain base models on train+val data\n",
    "best_rf_model.fit(X_train_full, y_train_full)\n",
    "best_nn_model.fit(X_train_full, y_train_full, nn__verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a837e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions from both models on test set and combine\n",
    "rf_test_preds = best_rf_model.predict_proba(X_test)[:,1]\n",
    "nn_test_preds = best_nn_model.predict_proba(X_test)[:,1]\n",
    "stacked_test_preds = np.column_stack((rf_test_preds, nn_test_preds))\n",
    "\n",
    "meta_probs = meta_model.predict_proba(stacked_test_preds)\n",
    "meta_y_proba = meta_probs[:, 1]\n",
    "meta_y_pred = (meta_y_proba > 0.5).astype(\"int32\")\n",
    "meta_acc = accuracy_score(y_test, meta_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a5af1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display validation accuracy\n",
    "print(f\"Validation Accuracy: {meta_acc:.4f}\")\n",
    "\n",
    "# confusion matrix\n",
    "meta_cm = confusion_matrix(y_test, meta_y_pred)\n",
    "labels = sorted(merged_1day['target'].unique())\n",
    "meta_cm_df = pd.DataFrame(meta_cm, index=labels, columns=labels)\n",
    "\n",
    "# classification report\n",
    "meta_cr = classification_report(y_test, meta_y_pred, output_dict=True)\n",
    "meta_cr_df = pd.DataFrame(meta_cr).transpose()\n",
    "for col in ['precision', 'recall', 'f1-score']:\n",
    "    meta_cr_df[col] = meta_cr_df[col].round(3)\n",
    "meta_cr_df['support'] = meta_cr_df['support'].astype(int)\n",
    "meta_cr_df.rename(index={'0': 'DOWN', '1': 'UP'}, inplace=True)\n",
    "\n",
    "# plot confusion matrix and classification report\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# confusion matrix on left\n",
    "axes[0].axis('off')\n",
    "table1 = axes[0].table(cellText=meta_cm_df.values,\n",
    "                       rowLabels=meta_cm_df.index,\n",
    "                       colLabels=meta_cm_df.columns,\n",
    "                       cellLoc='center',\n",
    "                       loc='center',\n",
    "                       rowLoc='center',\n",
    "                       colLoc='center',\n",
    "                       colWidths=[0.2]*len(meta_cm_df.columns)\n",
    ")\n",
    "\n",
    "table1.auto_set_font_size(False)\n",
    "table1.set_fontsize(18)\n",
    "table1.scale(1.2, 2.0)\n",
    "for key, cell in table1.get_celld().items():\n",
    "    cell.set_linewidth(1.2)\n",
    "    cell.set_edgecolor('gray')\n",
    "axes[0].set_title('Confusion Matrix - Stacked Model', fontsize=24, pad=20)\n",
    "\n",
    "# classification report on right\n",
    "axes[1].axis('off')\n",
    "\n",
    "table2 = axes[1].table(cellText=meta_cr_df.values,\n",
    "                       rowLabels=meta_cr_df.index,\n",
    "                       colLabels=meta_cr_df.columns,\n",
    "                       cellLoc='center',\n",
    "                       loc='center',\n",
    "                       rowLoc='center',\n",
    "                       colLoc='center',\n",
    "                       colWidths=[0.2]*len(meta_cr_df.columns)\n",
    ")\n",
    "\n",
    "table2.auto_set_font_size(False)\n",
    "table2.set_fontsize(16)\n",
    "table2.scale(1.2, 2.0)\n",
    "for key, cell in table2.get_celld().items():\n",
    "    cell.set_linewidth(1.2)\n",
    "    cell.set_edgecolor('gray')\n",
    "axes[1].set_title('Classification Report - Stacked Model', fontsize=24, pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('meta_confusion_and_classification_report.png', dpi=300,  bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf05c92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess cumulative returns by picking most likely UPs daily\n",
    "\n",
    "# create copy of merged_1day_test with results\n",
    "meta_test_results = merged_1day_test.copy()\n",
    "meta_test_results['prob_up'] = meta_y_proba\n",
    "\n",
    "# add daily % return column\n",
    "meta_test_results['daily_return_pct'] = ((meta_test_results['close'] - meta_test_results['prev_close']) / meta_test_results['prev_close']) * 100\n",
    "\n",
    "# sort by date and predicted probability\n",
    "meta_sorted_preds = meta_test_results.sort_values(by=['date', 'prob_up'], ascending=[True, False])\n",
    "\n",
    "# apply threshold filter (keep only confident picks)\n",
    "meta_sorted_preds = meta_sorted_preds[meta_sorted_preds['prob_up'] >= 0.6]\n",
    "\n",
    "# get top 5 (or fewer) picks per day\n",
    "meta_top5_daily = meta_sorted_preds.groupby('date').head(5)\n",
    "\n",
    "# calculate average return for the top picks per day\n",
    "meta_daily_avg_return = meta_top5_daily.groupby('date')['daily_return_pct'].mean().reset_index()\n",
    "meta_daily_avg_return.rename(columns={'daily_return_pct': 'avg_top5_return_pct'}, inplace=True)\n",
    "\n",
    "# compute cumulative return (compounded over time)\n",
    "meta_daily_avg_return['cumulative_return_pct'] = (1 + meta_daily_avg_return['avg_top5_return_pct'] / 100).cumprod() - 1\n",
    "meta_daily_avg_return['cumulative_return_pct'] *= 100  # back to percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5443ba29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with model returns\n",
    "meta_comparison = meta_daily_avg_return.merge(\n",
    "    sp500[['date', 'sp500_cum_return_pct']],\n",
    "    on='date',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfb14d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot stacked model returns and S&P 500 returns\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(\n",
    "    meta_comparison['date'], meta_comparison['cumulative_return_pct'],\n",
    "    label='Stacked Model Top 5 Picks',\n",
    "    color='blue', marker='o', linestyle='-')\n",
    "plt.plot(\n",
    "    nn_comparison['date'], nn_comparison['sp500_cum_return_pct'],\n",
    "    label='S&P 500',\n",
    "    color='black', marker='x', linestyle='--')\n",
    "\n",
    "plt.title(\"Stacked (RF + NN => LogReg) Cumulative Return: Model vs S&P 500\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Cumulative Return (%)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('new_meta_cumulative_return_comparison.png', format='png') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3664e2ed",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# plot distributions of predictions by true class\n",
    "y_test_array = np.array(y_test)\n",
    "\n",
    "# split the predicted probabilities based on true labels\n",
    "meta_probs_positive = meta_probs[y_test_array == 1]\n",
    "meta_probs_negative = meta_probs[y_test_array == 0]\n",
    "\n",
    "meta_probs_positive = meta_probs_positive.flatten()\n",
    "meta_probs_negative = meta_probs_negative.flatten()\n",
    "\n",
    "# Now plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(meta_probs_positive, bins=40, alpha=0.7, label='True Positive (UP)', color='blue', edgecolor='k')\n",
    "plt.hist(meta_probs_negative, bins=40, alpha=0.7, label='True Negative (DOWN)', color='red', edgecolor='k')\n",
    "\n",
    "plt.title('Stacked (RF + NN => LogReg) Distribution of Predicted Probabilities by True Class')\n",
    "plt.xlabel('Predicted Probability of Positive Class')\n",
    "plt.ylabel('Number of Test Instances')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "#plt.savefig('new_meta_prob_distribution_versus_true_class.png', format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ec56b9",
   "metadata": {},
   "source": [
    "## Summary of Model Performance: Cumulative Returns versus S&P 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32580b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot stacked model, RF, and NN returns with S&P 500 returns\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(\n",
    "    meta_comparison['date'], meta_comparison['cumulative_return_pct'],\n",
    "    label='Stacked Model Top 5 Picks',\n",
    "    color='blue', marker='o', linestyle='-')\n",
    "plt.plot(\n",
    "    rf_comparison['date'], rf_comparison['cumulative_return_pct'],\n",
    "    label='Random Forest Model Top 5 Picks',\n",
    "    color='green', marker='s', linestyle='-')\n",
    "plt.plot(\n",
    "    nn_comparison['date'], nn_comparison['cumulative_return_pct'],\n",
    "    label='Neural Network Model Top 5 Picks',\n",
    "    color='red', marker='^', linestyle='-')\n",
    "plt.plot(\n",
    "    nn_comparison['date'], nn_comparison['sp500_cum_return_pct'],\n",
    "    label='S&P 500',\n",
    "    color='black', marker='x', linestyle='--')\n",
    "\n",
    "plt.title(\"Summary Comparisions of Cumulative Return: Base Models and Meta Model vs S&P 500\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Cumulative Return (%)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('new_summary_cumulative_return_comparison.png', format='png') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97eb68e",
   "metadata": {},
   "source": [
    "## Correct Train/Val/Test Splits to be time-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904137a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative train tests split: temporally split, not random\n",
    "\n",
    "# Ensure 'date' column is in datetime format\n",
    "merged_1day['date'] = pd.to_datetime(merged_1day['date'])\n",
    "\n",
    "# Sort the dataframe by date\n",
    "merged_1day = merged_1day.sort_values(by='date').reset_index(drop=True)\n",
    "\n",
    "# Compute split indices\n",
    "n = len(merged_1day)\n",
    "train_end = int(0.6 * n)\n",
    "valid_end = int(0.8 * n)\n",
    "\n",
    "# Split the data\n",
    "train_set_time = merged_1day.iloc[:train_end]\n",
    "valid_set_time = merged_1day.iloc[train_end:valid_end]\n",
    "test_set_time  = merged_1day.iloc[valid_end:]\n",
    "\n",
    "# confirm date ranges\n",
    "print(\"Train range:\", train_set_time['date'].min(), \"to\", train_set_time['date'].max())\n",
    "print(\"Validation range:\", valid_set_time['date'].min(), \"to\", valid_set_time['date'].max())\n",
    "print(\"Test range:\", test_set_time['date'].min(), \"to\", test_set_time['date'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdd5aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preserve indices for retrieval of headline and price data after model evaluation\n",
    "train_indices = train_set_time.index\n",
    "valid_indices = valid_set_time.index\n",
    "test_indices = test_set_time.index\n",
    "\n",
    "# separate X and y\n",
    "X_train_time = train_set_time['headlines_prev_day_clean']\n",
    "X_val_time = valid_set_time['headlines_prev_day_clean']\n",
    "X_test_time = test_set_time['headlines_prev_day_clean']\n",
    "y_train_time = train_set_time['target'].map({'DOWN': 0, 'UP': 1}).astype(int)\n",
    "y_val_time = valid_set_time['target'].map({'DOWN': 0, 'UP': 1}).astype(int)\n",
    "y_test_time = test_set_time['target'].map({'DOWN': 0, 'UP': 1}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f697755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build pipeline\n",
    "rf_time_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('rf', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# parameter grid to search\n",
    "param_grid = {\n",
    "    'tfidf__max_features': [5000],\n",
    "    'rf__n_estimators': [400],\n",
    "    'rf__max_depth': [None]\n",
    "}\n",
    "\n",
    "# time series splitting is needed for temporal data\n",
    "n_splits = 5\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "# GridSearch\n",
    "rf_grid = GridSearchCV(\n",
    "    rf_time_pipeline,\n",
    "    param_grid,\n",
    "    cv=tscv,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023090f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit on the training set\n",
    "start = time.time()\n",
    "rf_grid.fit(X_train_time, y_train_time)\n",
    "train_time = time.time() - start\n",
    "print('Time required to tune model (min): {:.1f}'.format(train_time/60))\n",
    "\n",
    "# best model\n",
    "print(f\"Best RF Parameters: {rf_grid.best_params_}\")\n",
    "print(f\"Best RF CV Accuracy: {rf_grid.best_score_:.4f}\")\n",
    "\n",
    "# get the best pipeline\n",
    "best_rf_model = rf_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e21915",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_probs = best_rf_model.predict_proba(X_val_time)\n",
    "rf_y_proba = rf_probs[:, 1]\n",
    "rf_y_pred = (rf_y_proba > 0.5).astype(\"int32\")\n",
    "rf_acc = accuracy_score(y_val_time, rf_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173ed5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display validation accuracy\n",
    "print(f\"Validation Accuracy: {rf_acc:.4f}\")\n",
    "\n",
    "# confusion matrix\n",
    "rf_cm = confusion_matrix(y_val_time, rf_y_pred)\n",
    "labels = sorted(merged_1day['target'].unique())\n",
    "rf_cm_df = pd.DataFrame(rf_cm, index=labels, columns=labels)\n",
    "\n",
    "# classification report\n",
    "rf_cr = classification_report(y_val_time, rf_y_pred, output_dict=True)\n",
    "rf_cr_df = pd.DataFrame(rf_cr).transpose()\n",
    "for col in ['precision', 'recall', 'f1-score']:\n",
    "    rf_cr_df[col] = rf_cr_df[col].round(3)\n",
    "rf_cr_df['support'] = rf_cr_df['support'].astype(int)\n",
    "rf_cr_df.rename(index={'0': 'DOWN', '1': 'UP'}, inplace=True)\n",
    "\n",
    "# plot confusion matrix and classification report\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# confusion matrix on left\n",
    "axes[0].axis('off')\n",
    "table1 = axes[0].table(cellText=rf_cm_df.values,\n",
    "                       rowLabels=rf_cm_df.index,\n",
    "                       colLabels=rf_cm_df.columns,\n",
    "                       cellLoc='center',\n",
    "                       loc='center',\n",
    "                       rowLoc='center',\n",
    "                       colLoc='center',\n",
    "                       colWidths=[0.2]*len(rf_cm_df.columns)\n",
    ")\n",
    "\n",
    "table1.auto_set_font_size(False)\n",
    "table1.set_fontsize(18)\n",
    "table1.scale(1.2, 2.0)\n",
    "for key, cell in table1.get_celld().items():\n",
    "    cell.set_linewidth(1.2)\n",
    "    cell.set_edgecolor('gray')\n",
    "axes[0].set_title('Confusion Matrix - Random Forest (corrected)', fontsize=24, pad=20)\n",
    "\n",
    "# classification report on right\n",
    "axes[1].axis('off')\n",
    "\n",
    "table2 = axes[1].table(cellText=rf_cr_df.values,\n",
    "                       rowLabels=rf_cr_df.index,\n",
    "                       colLabels=rf_cr_df.columns,\n",
    "                       cellLoc='center',\n",
    "                       loc='center',\n",
    "                       rowLoc='center',\n",
    "                       colLoc='center',\n",
    "                       colWidths=[0.2]*len(rf_cr_df.columns)\n",
    ")\n",
    "\n",
    "table2.auto_set_font_size(False)\n",
    "table2.set_fontsize(16)\n",
    "table2.scale(1.2, 2.0)\n",
    "for key, cell in table2.get_celld().items():\n",
    "    cell.set_linewidth(1.2)\n",
    "    cell.set_edgecolor('gray')\n",
    "axes[1].set_title('Classification Report - Random Forest (corrected)', fontsize=24, pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('new_rf_confusion_and_classification_report.png', dpi=300,  bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b48f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess cumulative returns by picking most likely UPs daily\n",
    "\n",
    "# create copy of merged_1day_val with results\n",
    "rf_val_results = valid_set_time.copy()\n",
    "rf_val_results['prob_up'] = rf_y_proba\n",
    "\n",
    "# add daily % return column\n",
    "rf_val_results['daily_return_pct'] = ((rf_val_results['close'] - rf_val_results['prev_close']) / rf_val_results['prev_close']) * 100\n",
    "\n",
    "# sort by date and predicted probability\n",
    "rf_sorted_preds = rf_val_results.sort_values(by=['date', 'prob_up'], ascending=[True, False])\n",
    "\n",
    "# apply threshold filter (keep only confident picks)\n",
    "rf_sorted_preds = rf_sorted_preds[rf_sorted_preds['prob_up'] >= 0.6]\n",
    "\n",
    "# get top 5 (or fewer) picks per day\n",
    "rf_top5_daily = rf_sorted_preds.groupby('date').head(5)\n",
    "\n",
    "# calculate average return for the top picks per day\n",
    "rf_daily_avg_return = rf_top5_daily.groupby('date')['daily_return_pct'].mean().reset_index()\n",
    "rf_daily_avg_return.rename(columns={'daily_return_pct': 'avg_top5_return_pct'}, inplace=True)\n",
    "\n",
    "# compute cumulative return (compounded over time)\n",
    "rf_daily_avg_return['cumulative_return_pct'] = (1 + rf_daily_avg_return['avg_top5_return_pct'] / 100).cumprod() - 1\n",
    "rf_daily_avg_return['cumulative_return_pct'] *= 100  # back to percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32174344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build S&P 500 comparison\n",
    "\n",
    "# get S&P 500 data for the same date range\n",
    "start_date_val = rf_daily_avg_return['date'].min()\n",
    "end_date_val = rf_daily_avg_return['date'].max()\n",
    "sp500_val = yf.download(\"^GSPC\", start=start_date_val, end=end_date_val)\n",
    "\n",
    "# ensure index is datetime and trimmed to match your data\n",
    "sp500_val = sp500_val[['Open', 'Close']]\n",
    "sp500_val = sp500_val.reset_index()  # brings 'Date' into a column\n",
    "sp500_val.rename(columns={'Date': 'date'}, inplace=True)  # match column name with daily_avg_return\n",
    "\n",
    "# prepare the S&P 500 daily % returns and cumulative return\n",
    "sp500_val['daily_return_pct'] = ((sp500_val['Close'] - sp500_val['Open']) / sp500_val['Open']) * 100\n",
    "sp500_val['sp500_cum_return_pct'] = (1 + sp500_val['daily_return_pct'] / 100).cumprod() - 1\n",
    "sp500_val['sp500_cum_return_pct'] *= 100\n",
    "\n",
    "# ensure sp500 'date' is datetime type\n",
    "sp500_val['date'] = pd.to_datetime(sp500_val['date'])\n",
    "\n",
    "# flatten sp500 multi-level columns (if any)\n",
    "sp500_val.columns = [col if isinstance(col, str) else col[0] for col in sp500.columns]\n",
    "\n",
    "# merge with your returns\n",
    "rf_comparison = rf_daily_avg_return.merge(\n",
    "    sp500_val[['date', 'sp500_cum_return_pct']],\n",
    "    on='date',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24565d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot rf model returns and S&P 500 returns\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(\n",
    "    rf_comparison['date'], rf_comparison['cumulative_return_pct'],\n",
    "    label='Random Forest Model Top 5 Picks',\n",
    "    color='green', marker='s', linestyle='-')\n",
    "plt.plot(\n",
    "    rf_comparison['date'], rf_comparison['sp500_cum_return_pct'],\n",
    "    label='S&P 500',\n",
    "    color='black', marker='x', linestyle='--')\n",
    "\n",
    "plt.title(\"Random Forest Cumulative Return: Model vs S&P 500\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Cumulative Return (%)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('time_corrected_rf_cumulative_return_comparison.png', format='png') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540376e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distributions of predictions by true class\n",
    "y_val_array = np.array(y_val_time)\n",
    "\n",
    "# Then split the predicted probabilities based on true labels\n",
    "probs_positive = rf_probs[y_val_array == 1]\n",
    "probs_negative = rf_probs[y_val_array == 0]\n",
    "\n",
    "probs_positive = probs_positive.flatten()\n",
    "probs_negative = probs_negative.flatten()\n",
    "\n",
    "# Now plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(probs_positive, bins=40, alpha=0.7, label='True Positive (UP)', color='blue', edgecolor='k')\n",
    "plt.hist(probs_negative, bins=40, alpha=0.7, label='True Negative (DOWN)', color='red', edgecolor='k')\n",
    "\n",
    "plt.title('Random Forest Distribution of Predicted Probabilities by True Class (corrected)')\n",
    "plt.xlabel('Predicted Probability of Positive Class')\n",
    "plt.ylabel('Number of Test Instances')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "#plt.savefig('time_corrected_rf_prob_distribution_versus_true_class.png', format='png') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f00a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid CNN-LTSM Model\n",
    "\n",
    "# --- Custom transformer to tokenize and pad sequences ---\n",
    "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, num_words=10000, max_len=40):\n",
    "        self.num_words = num_words\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.tokenizer = Tokenizer(num_words=self.num_words, oov_token=\"<OOV>\")\n",
    "        self.tokenizer.fit_on_texts(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        sequences = self.tokenizer.texts_to_sequences(X)\n",
    "        padded = pad_sequences(sequences, maxlen=self.max_len, padding='post', truncating='post')\n",
    "        return padded\n",
    "\n",
    "\n",
    "def build_cnn_lstm_model(vocab_size=10000, embedding_dim=100, input_length=40, l2_reg=0.01, dropout_rate=0.5):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_length,)))\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim))\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(LSTM(64, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_regularizer=regularizers.l2(l2_reg)))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e257e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hybrid cnn-lstm pipeline\n",
    "cnn_lstm_pipeline = Pipeline([\n",
    "    ('preprocess', TextPreprocessor(num_words=10000, max_len=40)),\n",
    "    ('clf', KerasClassifier(\n",
    "        model=build_cnn_lstm_model,\n",
    "        model__vocab_size=10000,\n",
    "        model__embedding_dim=100,\n",
    "        model__input_length=40,\n",
    "        model__l2_reg=0.01,\n",
    "        model__dropout_rate=0.5,\n",
    "        epochs=10,\n",
    "        batch_size=32,\n",
    "        verbose=0,\n",
    "        shuffle=False,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# gridsearch setup\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "param_grid = {\n",
    "    'clf__batch_size': [32],\n",
    "    'clf__epochs': [10],\n",
    "    'clf__model__l2_reg': [0.01],\n",
    "    'clf__model__dropout_rate': [0.3],\n",
    "}\n",
    "\n",
    "# define gridsearch\n",
    "grid_search = GridSearchCV(\n",
    "    cnn_lstm_pipeline,\n",
    "    param_grid,\n",
    "    cv=tscv,\n",
    "    scoring='accuracy',\n",
    "    verbose=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cd70f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit on training set\n",
    "start = time.time()\n",
    "grid_search.fit(X_train_time, y_train_time)\n",
    "train_time = time.time() - start\n",
    "print(f\"Training time (min): {train_time / 60:.1f}\")\n",
    "\n",
    "print(\"Best Params:\", grid_search.best_params_)\n",
    "print(f\"Best CV Accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# get the best pipeline\n",
    "best_hybrid_cnn_lstm_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c732a191",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_probs = best_hybrid_cnn_lstm_model.predict_proba(X_val_time)\n",
    "cnn_y_proba = cnn_probs[:, 1]\n",
    "cnn_y_pred = (cnn_y_proba > 0.5).astype(\"int32\")\n",
    "cnn_acc = accuracy_score(y_val_time, cnn_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725ed2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display validation accuracy\n",
    "print(f\"Validation Accuracy: {cnn_acc:.4f}\")\n",
    "\n",
    "# confusion matrix\n",
    "cnn_cm = confusion_matrix(y_val_time, cnn_y_pred)\n",
    "labels = sorted(merged_1day['target'].unique())\n",
    "cnn_cm_df = pd.DataFrame(cnn_cm, index=labels, columns=labels)\n",
    "\n",
    "# classification report\n",
    "cnn_cr = classification_report(y_val_time, cnn_y_pred, output_dict=True)\n",
    "cnn_cr_df = pd.DataFrame(cnn_cr).transpose()\n",
    "for col in ['precision', 'recall', 'f1-score']:\n",
    "    cnn_cr_df[col] = cnn_cr_df[col].round(4)\n",
    "cnn_cr_df['support'] = cnn_cr_df['support'].astype(int)\n",
    "cnn_cr_df.rename(index={'0': 'DOWN', '1': 'UP'}, inplace=True)\n",
    "\n",
    "# plot confusion matrix and classification report\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# confusion matrix on left\n",
    "axes[0].axis('off')\n",
    "table1 = axes[0].table(cellText=cnn_cm_df.values,\n",
    "                       rowLabels=cnn_cm_df.index,\n",
    "                       colLabels=cnn_cm_df.columns,\n",
    "                       cellLoc='center',\n",
    "                       loc='center',\n",
    "                       rowLoc='center',\n",
    "                       colLoc='center',\n",
    "                       colWidths=[0.2]*len(cnn_cm_df.columns)\n",
    ")\n",
    "\n",
    "table1.auto_set_font_size(False)\n",
    "table1.set_fontsize(18)\n",
    "table1.scale(1.2, 2.0)\n",
    "for key, cell in table1.get_celld().items():\n",
    "    cell.set_linewidth(1.2)\n",
    "    cell.set_edgecolor('gray')\n",
    "axes[0].set_title('Confusion Matrix - Hybrid CNN-LSTM', fontsize=24, pad=20)\n",
    "\n",
    "# classification report on right\n",
    "axes[1].axis('off')\n",
    "\n",
    "table2 = axes[1].table(cellText=cnn_cr_df.values,\n",
    "                       rowLabels=cnn_cr_df.index,\n",
    "                       colLabels=cnn_cr_df.columns,\n",
    "                       cellLoc='center',\n",
    "                       loc='center',\n",
    "                       rowLoc='center',\n",
    "                       colLoc='center',\n",
    "                       colWidths=[0.2]*len(cnn_cr_df.columns)\n",
    ")\n",
    "\n",
    "table2.auto_set_font_size(False)\n",
    "table2.set_fontsize(16)\n",
    "table2.scale(1.2, 2.0)\n",
    "for key, cell in table2.get_celld().items():\n",
    "    cell.set_linewidth(1.2)\n",
    "    cell.set_edgecolor('gray')\n",
    "axes[1].set_title('Classification Report - Hybrid CNN-LSTM', fontsize=24, pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('time_corrected_cnn_lstm_confusion_and_classification_report.png', dpi=300,  bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38123fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess cumulative returns by picking most likely UPs daily\n",
    "\n",
    "# create copy of merged_1day_val with results\n",
    "cnn_val_results = valid_set_time.copy()\n",
    "cnn_val_results['prob_up'] = cnn_y_proba\n",
    "\n",
    "# add daily % return column\n",
    "cnn_val_results['daily_return_pct'] = ((cnn_val_results['close'] - cnn_val_results['prev_close']) / cnn_val_results['prev_close']) * 100\n",
    "\n",
    "# sort by date and predicted probability\n",
    "cnn_sorted_preds = cnn_val_results.sort_values(by=['date', 'prob_up'], ascending=[True, False])\n",
    "\n",
    "# apply threshold filter (keep only confident picks)\n",
    "cnn_sorted_preds = cnn_sorted_preds[cnn_sorted_preds['prob_up'] >= 0.6]\n",
    "\n",
    "# get top 5 (or fewer) picks per day\n",
    "cnn_top5_daily = cnn_sorted_preds.groupby('date').head(5)\n",
    "\n",
    "# calculate average return for the top picks per day\n",
    "cnn_daily_avg_return = cnn_top5_daily.groupby('date')['daily_return_pct'].mean().reset_index()\n",
    "cnn_daily_avg_return.rename(columns={'daily_return_pct': 'avg_top5_return_pct'}, inplace=True)\n",
    "\n",
    "# compute cumulative return (compounded over time)\n",
    "cnn_daily_avg_return['cumulative_return_pct'] = (1 + cnn_daily_avg_return['avg_top5_return_pct'] / 100).cumprod() - 1\n",
    "cnn_daily_avg_return['cumulative_return_pct'] *= 100  # back to percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c542e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with model returns\n",
    "cnn_comparison = cnn_daily_avg_return.merge(\n",
    "    sp500_val[['date', 'sp500_cum_return_pct']],\n",
    "    on='date',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cab41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot nn model returns and S&P 500 returns\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(cnn_comparison['date'], cnn_comparison['cumulative_return_pct'],\n",
    "         label='Neural Network Model Top 5 Picks',\n",
    "         color='red', marker='^', linestyle='-')\n",
    "plt.plot(cnn_comparison['date'], cnn_comparison['sp500_cum_return_pct'],\n",
    "         label='S&P 500',\n",
    "         color='black', marker='x', linestyle='--')\n",
    "\n",
    "plt.title(\"Hybrid CNN-LSTM Cumulative Return: Model vs S&P 500\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Cumulative Return (%)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('time_corrected_cnn_lstm_cumulative_return_comparison.png', format='png') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9e8320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distributions of predictions by true class\n",
    "\n",
    "# split the predicted probabilities based on true labels\n",
    "cnn_probs_positive = cnn_probs[y_val_array == 1]\n",
    "cnn_probs_negative = cnn_probs[y_val_array == 0]\n",
    "\n",
    "cnn_probs_positive = cnn_probs_positive.flatten()\n",
    "cnn_probs_negative = cnn_probs_negative.flatten()\n",
    "\n",
    "# Now plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(cnn_probs_positive, bins=40, alpha=0.7, label='True Positive (UP)', color='blue', edgecolor='k')\n",
    "plt.hist(cnn_probs_negative, bins=40, alpha=0.7, label='True Negative (DOWN)', color='red', edgecolor='k')\n",
    "\n",
    "plt.title('Hybrid CNN-LSTM Distribution of Predicted Probabilities by True Class')\n",
    "plt.xlabel('Predicted Probability of Positive Class')\n",
    "plt.ylabel('Number of Test Instances')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "#plt.savefig('time_corrected_cnn_lstm_prob_distribution_versus_true_class.png', format='png') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388bd673",
   "metadata": {},
   "source": [
    "## Stacked Model with Time-corrected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba3c063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge train and val sets\n",
    "X_train_time_full = pd.concat([X_train_time, X_val_time], axis=0)\n",
    "y_train_time_full = pd.concat([y_train_time, y_val_time], axis=0)\n",
    "\n",
    "# prepare base model clones (to avoid leakage)\n",
    "base_model_1 = clone(best_rf_model)\n",
    "base_model_2 = clone(best_hybrid_cnn_lstm_model)\n",
    "\n",
    "# initialize out-of-fold prediction arrays\n",
    "n_splits = 5\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "oof_preds_rf = np.zeros(len(X_train_time_full))\n",
    "oof_preds_cnn = np.zeros(len(X_train_time_full))\n",
    "\n",
    "# loop through folds\n",
    "for fold, (train_idx, val_idx) in enumerate(tscv.split(X_train_time_full, y_train_time_full)):\n",
    "    print(f\"Training fold {fold + 1}/{n_splits}...\")\n",
    "    \n",
    "    # split data\n",
    "    X_tr, X_val_fold = X_train_time_full.iloc[train_idx], X_train_time_full.iloc[val_idx]\n",
    "    y_tr, y_val_fold = y_train_time_full.iloc[train_idx], y_train_time_full.iloc[val_idx]\n",
    "    \n",
    "    # train both base models\n",
    "    model_rf = clone(base_model_1)\n",
    "    model_cnn = clone(base_model_2)\n",
    "\n",
    "    model_rf.fit(X_tr, y_tr)\n",
    "    model_cnn.fit(X_tr, y_tr, clf__verbose=0)\n",
    "\n",
    "    # get validation predictions\n",
    "    oof_preds_rf[val_idx] = model_rf.predict_proba(X_val_fold)[:, 1]\n",
    "    oof_preds_cnn[val_idx] = model_cnn.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "# stack OOF predictions together\n",
    "stacked_oof_preds = np.column_stack((oof_preds_rf, oof_preds_cnn))\n",
    "\n",
    "# train meta-model\n",
    "meta_model = LogisticRegression()\n",
    "meta_model.fit(stacked_oof_preds, y_train_time_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2cf190",
   "metadata": {},
   "source": [
    "## Before retraining base models, get test set performance of each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21507d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish rf and cnn probs on test data\n",
    "rf_test_probs = best_rf_model.predict_proba(X_test_time)\n",
    "rf_y_test_proba = rf_test_probs[:, 1]\n",
    "rf_y_test_pred = (rf_y_test_proba > 0.5).astype(\"int32\")\n",
    "rf_test_acc = accuracy_score(y_test_time, rf_y_test_pred)\n",
    "\n",
    "cnn_test_probs = best_hybrid_cnn_lstm_model.predict_proba(X_test_time)\n",
    "cnn_y_test_proba = cnn_test_probs[:, 1]\n",
    "cnn_y_test_pred = (cnn_y_test_proba > 0.5).astype(\"int32\")\n",
    "cnn_test_acc = accuracy_score(y_test_time, cnn_y_test_pred)\n",
    "\n",
    "# create copy of merged_1day_test with results\n",
    "rf_test_results = test_set_time.copy()\n",
    "cnn_test_results = test_set_time.copy()\n",
    "rf_test_results['prob_up'] = rf_y_test_proba\n",
    "cnn_test_results['prob_up'] = cnn_y_test_proba\n",
    "\n",
    "# add daily % return column\n",
    "rf_test_results['daily_return_pct'] = ((rf_test_results['close'] - rf_test_results['prev_close']) / rf_test_results['prev_close']) * 100\n",
    "cnn_test_results['daily_return_pct'] = ((cnn_test_results['close'] - cnn_test_results['prev_close']) / cnn_test_results['prev_close']) * 100\n",
    "\n",
    "# sort by date and predicted probability\n",
    "rf_test_sorted_preds = rf_test_results.sort_values(by=['date', 'prob_up'], ascending=[True, False])\n",
    "cnn_test_sorted_preds = cnn_test_results.sort_values(by=['date', 'prob_up'], ascending=[True, False])\n",
    "\n",
    "# apply threshold filter (keep only confident picks)\n",
    "rf_test_sorted_preds = rf_test_sorted_preds[rf_test_sorted_preds['prob_up'] >= 0.6]\n",
    "cnn_test_sorted_preds = cnn_test_sorted_preds[cnn_test_sorted_preds['prob_up'] >= 0.6]\n",
    "\n",
    "# get top 5 (or fewer) picks per day\n",
    "rf_test_top5_daily = rf_test_sorted_preds.groupby('date').head(5)\n",
    "cnn_test_top5_daily = cnn_test_sorted_preds.groupby('date').head(5)\n",
    "\n",
    "# calculate average return for the top picks per day\n",
    "rf_test_daily_avg_return = rf_test_top5_daily.groupby('date')['daily_return_pct'].mean().reset_index()\n",
    "cnn_test_daily_avg_return = cnn_test_top5_daily.groupby('date')['daily_return_pct'].mean().reset_index()\n",
    "rf_test_daily_avg_return.rename(columns={'daily_return_pct': 'avg_top5_return_pct'}, inplace=True)\n",
    "cnn_test_daily_avg_return.rename(columns={'daily_return_pct': 'avg_top5_return_pct'}, inplace=True)\n",
    "\n",
    "# compute cumulative return (compounded over time)\n",
    "rf_test_daily_avg_return['cumulative_return_pct'] = (1 + rf_test_daily_avg_return['avg_top5_return_pct'] / 100).cumprod() - 1\n",
    "cnn_test_daily_avg_return['cumulative_return_pct'] = (1 + cnn_test_daily_avg_return['avg_top5_return_pct'] / 100).cumprod() - 1\n",
    "rf_test_daily_avg_return['cumulative_return_pct'] *= 100  # back to percent\n",
    "cnn_test_daily_avg_return['cumulative_return_pct'] *= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751b98da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain base models on train+val data\n",
    "updated_rf_base_model = best_rf_model.fit(X_train_time_full, y_train_time_full)\n",
    "updated_cnn_base_model = best_hybrid_cnn_lstm_model.fit(X_train_time_full, y_train_time_full, clf__verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813e6163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get updated base model predictions on full train+val set\n",
    "rf_trainval_preds = updated_rf_base_model.predict_proba(X_train_time_full)[:, 1]\n",
    "cnn_trainval_preds = updated_cnn_base_model.predict_proba(X_train_time_full)[:, 1]\n",
    "stacked_trainval_preds = np.column_stack((rf_trainval_preds, cnn_trainval_preds))\n",
    "\n",
    "# train meta-model on updated predictions\n",
    "meta_model.fit(stacked_trainval_preds, y_train_time_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4378e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions from both models on test set and combine\n",
    "rf_test_preds = updated_rf_base_model.predict_proba(X_test_time)[:,1]\n",
    "cnn_test_preds = updated_cnn_base_model.predict_proba(X_test_time)[:,1]\n",
    "stacked_test_preds = np.column_stack((rf_test_preds, cnn_test_preds))\n",
    "\n",
    "meta_probs = meta_model.predict_proba(stacked_test_preds)\n",
    "meta_y_proba = meta_probs[:, 1]\n",
    "meta_y_pred = (meta_y_proba > 0.5).astype(\"int32\")\n",
    "meta_acc = accuracy_score(y_test_time, meta_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4337a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display validation accuracy\n",
    "print(f\"Validation Accuracy: {meta_acc:.4f}\")\n",
    "\n",
    "# confusion matrix\n",
    "meta_cm = confusion_matrix(y_test_time, meta_y_pred)\n",
    "labels = sorted(merged_1day['target'].unique())\n",
    "meta_cm_df = pd.DataFrame(meta_cm, index=labels, columns=labels)\n",
    "\n",
    "# classification report\n",
    "meta_cr = classification_report(y_test_time, meta_y_pred, output_dict=True)\n",
    "meta_cr_df = pd.DataFrame(meta_cr).transpose()\n",
    "for col in ['precision', 'recall', 'f1-score']:\n",
    "    meta_cr_df[col] = meta_cr_df[col].round(3)\n",
    "meta_cr_df['support'] = meta_cr_df['support'].astype(int)\n",
    "meta_cr_df.rename(index={'0': 'DOWN', '1': 'UP'}, inplace=True)\n",
    "\n",
    "# plot confusion matrix and classification report\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# confusion matrix on left\n",
    "axes[0].axis('off')\n",
    "table1 = axes[0].table(cellText=meta_cm_df.values,\n",
    "                       rowLabels=meta_cm_df.index,\n",
    "                       colLabels=meta_cm_df.columns,\n",
    "                       cellLoc='center',\n",
    "                       loc='center',\n",
    "                       rowLoc='center',\n",
    "                       colLoc='center',\n",
    "                       colWidths=[0.2]*len(meta_cm_df.columns)\n",
    ")\n",
    "\n",
    "table1.auto_set_font_size(False)\n",
    "table1.set_fontsize(18)\n",
    "table1.scale(1.2, 2.0)\n",
    "for key, cell in table1.get_celld().items():\n",
    "    cell.set_linewidth(1.2)\n",
    "    cell.set_edgecolor('gray')\n",
    "axes[0].set_title('Confusion Matrix - Stacked Model (corrected)', fontsize=24, pad=20)\n",
    "\n",
    "# classification report on right\n",
    "axes[1].axis('off')\n",
    "\n",
    "table2 = axes[1].table(cellText=meta_cr_df.values,\n",
    "                       rowLabels=meta_cr_df.index,\n",
    "                       colLabels=meta_cr_df.columns,\n",
    "                       cellLoc='center',\n",
    "                       loc='center',\n",
    "                       rowLoc='center',\n",
    "                       colLoc='center',\n",
    "                       colWidths=[0.2]*len(meta_cr_df.columns)\n",
    ")\n",
    "\n",
    "table2.auto_set_font_size(False)\n",
    "table2.set_fontsize(16)\n",
    "table2.scale(1.2, 2.0)\n",
    "for key, cell in table2.get_celld().items():\n",
    "    cell.set_linewidth(1.2)\n",
    "    cell.set_edgecolor('gray')\n",
    "axes[1].set_title('Classification Report - Stacked Model (corrected)', fontsize=24, pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('time_corrected_meta_confusion_and_classification_report.png', dpi=300,  bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c93912b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess cumulative returns by picking most likely UPs daily\n",
    "\n",
    "# create copy of merged_1day_test with results\n",
    "meta_test_results = test_set_time.copy()\n",
    "meta_test_results['prob_up'] = meta_y_proba\n",
    "\n",
    "# add daily % return column\n",
    "meta_test_results['daily_return_pct'] = ((meta_test_results['close'] - meta_test_results['prev_close']) / meta_test_results['prev_close']) * 100\n",
    "\n",
    "# sort by date and predicted probability\n",
    "meta_sorted_preds = meta_test_results.sort_values(by=['date', 'prob_up'], ascending=[True, False])\n",
    "\n",
    "# apply threshold filter (keep only confident picks)\n",
    "meta_sorted_preds = meta_sorted_preds[meta_sorted_preds['prob_up'] >= 0.6]\n",
    "\n",
    "# get top 5 (or fewer) picks per day\n",
    "meta_top5_daily = meta_sorted_preds.groupby('date').head(5)\n",
    "\n",
    "# calculate average return for the top picks per day\n",
    "meta_daily_avg_return = meta_top5_daily.groupby('date')['daily_return_pct'].mean().reset_index()\n",
    "meta_daily_avg_return.rename(columns={'daily_return_pct': 'avg_top5_return_pct'}, inplace=True)\n",
    "\n",
    "# compute cumulative return (compounded over time)\n",
    "meta_daily_avg_return['cumulative_return_pct'] = (1 + meta_daily_avg_return['avg_top5_return_pct'] / 100).cumprod() - 1\n",
    "meta_daily_avg_return['cumulative_return_pct'] *= 100  # back to percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2992ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build S&P 500 comparison\n",
    "\n",
    "# get S&P 500 data for the same date range\n",
    "start_date_test = meta_daily_avg_return['date'].min()\n",
    "end_date_test = meta_daily_avg_return['date'].max()\n",
    "sp500_test = yf.download(\"^GSPC\", start=start_date_test, end=end_date_test)\n",
    "sp500_test.index = sp500_test.index.tz_localize(None)\n",
    "\n",
    "# ensure index is datetime and trimmed to match your data\n",
    "sp500_test = sp500_test[['Open', 'Close']]\n",
    "sp500_test = sp500_test.reset_index()  # brings 'Date' into a column\n",
    "sp500_test.rename(columns={'Date': 'date'}, inplace=True)  # match column name with daily_avg_return\n",
    "\n",
    "# prepare the S&P 500 daily % returns and cumulative return\n",
    "sp500_test['daily_return_pct'] = ((sp500_test['Close'] - sp500_test['Open']) / sp500_test['Open']) * 100\n",
    "sp500_test['sp500_cum_return_pct'] = (1 + sp500_test['daily_return_pct'] / 100).cumprod() - 1\n",
    "sp500_test['sp500_cum_return_pct'] *= 100\n",
    "\n",
    "# ensure sp500 'date' is datetime type\n",
    "sp500_test['date'] = pd.to_datetime(sp500_test['date'])\n",
    "\n",
    "# flatten sp500 multi-level columns (if any)\n",
    "sp500_test.columns = [col if isinstance(col, str) else col[0] for col in sp500_test.columns]\n",
    "\n",
    "# merge with returns\n",
    "meta_comparison = meta_daily_avg_return.merge(\n",
    "    sp500_test[['date', 'sp500_cum_return_pct']],\n",
    "    on='date',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "rf_test_comparison = rf_test_daily_avg_return.merge(\n",
    "    sp500_test[['date', 'sp500_cum_return_pct']],\n",
    "    on='date',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "cnn_test_comparison = cnn_test_daily_avg_return.merge(\n",
    "    sp500_test[['date', 'sp500_cum_return_pct']],\n",
    "    on='date',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cf535b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot stacked model returns and S&P 500 returns\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(\n",
    "    meta_comparison['date'], meta_comparison['cumulative_return_pct'],\n",
    "    label='Stacked Model Top 5 Picks',\n",
    "    color='blue', marker='o', linestyle='-')\n",
    "plt.plot(\n",
    "    meta_comparison['date'], meta_comparison['sp500_cum_return_pct'],\n",
    "    label='S&P 500',\n",
    "    color='black', marker='x', linestyle='--')\n",
    "\n",
    "plt.title(\"Stacked (RF + CNN => LogReg) Cumulative Return: Model vs S&P 500\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Cumulative Return (%)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('time_corrected_meta_cumulative_return_comparison.png', format='png') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d32de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distributions of predictions by true class\n",
    "y_test_array = np.array(y_test_time)\n",
    "\n",
    "# split the predicted probabilities based on true labels\n",
    "meta_probs_positive = meta_probs[y_test_array == 1]\n",
    "meta_probs_negative = meta_probs[y_test_array == 0]\n",
    "\n",
    "meta_probs_positive = meta_probs_positive.flatten()\n",
    "meta_probs_negative = meta_probs_negative.flatten()\n",
    "\n",
    "# Now plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(meta_probs_positive, bins=40, alpha=0.7, label='True Positive (UP)', color='blue', edgecolor='k')\n",
    "plt.hist(meta_probs_negative, bins=40, alpha=0.7, label='True Negative (DOWN)', color='red', edgecolor='k')\n",
    "\n",
    "plt.title('Stacked (RF + CNN-LSTM => LogReg) Distribution of Predicted Probabilities by True Class')\n",
    "plt.xlabel('Predicted Probability of Positive Class')\n",
    "plt.ylabel('Number of Test Instances')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "#plt.savefig('time_corrected_meta_prob_distribution_versus_true_class.png', format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041df9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot stacked model, RF, and NN returns with S&P 500 returns\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(\n",
    "    meta_comparison['date'], meta_comparison['cumulative_return_pct'],\n",
    "    label='Stacked Model Top 5 Picks',\n",
    "    color='blue', marker='o', linestyle='-')\n",
    "plt.plot(\n",
    "    rf_test_comparison['date'], rf_test_comparison['cumulative_return_pct'],\n",
    "    label='Random Forest Model Top 5 Picks',\n",
    "    color='green', marker='s', linestyle='-')\n",
    "plt.plot(\n",
    "    cnn_test_comparison['date'], cnn_test_comparison['cumulative_return_pct'],\n",
    "    label='CNN-LSTM Model Top 5 Picks',\n",
    "    color='red', marker='^', linestyle='-')\n",
    "plt.plot(\n",
    "    meta_comparison['date'], meta_comparison['sp500_cum_return_pct'],\n",
    "    label='S&P 500',\n",
    "    color='black', marker='x', linestyle='--')\n",
    "\n",
    "plt.title(\"Summary Comparisions of Cumulative Return: Base Models and Meta Model vs S&P 500\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Cumulative Return (%)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('time_corrected_summary_cumulative_return_comparison.png', format='png') \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
